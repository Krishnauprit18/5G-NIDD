{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOjDGNw5qTz0uM3cgzLv1Wu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xc08HnzmNjwA","executionInfo":{"status":"ok","timestamp":1690253513277,"user_tz":-330,"elapsed":23238,"user":{"displayName":"Krishna Uprit","userId":"12130931885403965088"}},"outputId":"0974306d-9722-424e-ae5f-70db2bc233eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","6/6 [==============================] - 3s 314ms/step - loss: 935717.2500 - accuracy: 0.0818 - val_loss: 10213.6465 - val_accuracy: 0.8140\n","Epoch 2/100\n","6/6 [==============================] - 0s 22ms/step - loss: 51931.4609 - accuracy: 0.8993 - val_loss: 7026.1133 - val_accuracy: 0.9070\n","Epoch 3/100\n","6/6 [==============================] - 0s 17ms/step - loss: 7155.1934 - accuracy: 0.9212 - val_loss: 9555.1289 - val_accuracy: 0.9070\n","Epoch 4/100\n","6/6 [==============================] - 0s 25ms/step - loss: 8726.2998 - accuracy: 0.9212 - val_loss: 10341.5518 - val_accuracy: 0.9070\n","Epoch 5/100\n","6/6 [==============================] - 0s 18ms/step - loss: 9232.2803 - accuracy: 0.9212 - val_loss: 10382.6611 - val_accuracy: 0.9070\n","Epoch 6/100\n","6/6 [==============================] - 0s 11ms/step - loss: 9123.7695 - accuracy: 0.9212 - val_loss: 9901.3115 - val_accuracy: 0.9070\n","Epoch 7/100\n","6/6 [==============================] - 0s 11ms/step - loss: 8594.9092 - accuracy: 0.9212 - val_loss: 9188.7695 - val_accuracy: 0.9070\n","Epoch 8/100\n","6/6 [==============================] - 0s 11ms/step - loss: 7872.1606 - accuracy: 0.9212 - val_loss: 8221.5635 - val_accuracy: 0.9070\n","Epoch 9/100\n","6/6 [==============================] - 0s 11ms/step - loss: 6979.7754 - accuracy: 0.9212 - val_loss: 7086.6909 - val_accuracy: 0.9070\n","Epoch 10/100\n","6/6 [==============================] - 0s 14ms/step - loss: 6003.3218 - accuracy: 0.9212 - val_loss: 5845.7705 - val_accuracy: 0.9070\n","Epoch 11/100\n","6/6 [==============================] - 0s 15ms/step - loss: 4866.4277 - accuracy: 0.9212 - val_loss: 4600.4272 - val_accuracy: 0.9070\n","Epoch 12/100\n","6/6 [==============================] - 0s 17ms/step - loss: 3775.3899 - accuracy: 0.9212 - val_loss: 3266.5476 - val_accuracy: 0.9070\n","Epoch 13/100\n","6/6 [==============================] - 0s 15ms/step - loss: 2685.5034 - accuracy: 0.9212 - val_loss: 1931.7069 - val_accuracy: 0.9070\n","Epoch 14/100\n","6/6 [==============================] - 0s 11ms/step - loss: 1479.1564 - accuracy: 0.9212 - val_loss: 429.0790 - val_accuracy: 0.9070\n","Epoch 15/100\n","6/6 [==============================] - 0s 12ms/step - loss: 856.0750 - accuracy: 0.8131 - val_loss: 560.1735 - val_accuracy: 0.9070\n","Epoch 16/100\n","6/6 [==============================] - 0s 14ms/step - loss: 859.9707 - accuracy: 0.9212 - val_loss: 711.0495 - val_accuracy: 0.9070\n","Epoch 17/100\n","6/6 [==============================] - 0s 11ms/step - loss: 697.0475 - accuracy: 0.9212 - val_loss: 160.9733 - val_accuracy: 0.9302\n","Epoch 18/100\n","6/6 [==============================] - 0s 15ms/step - loss: 576.7027 - accuracy: 0.8569 - val_loss: 503.2279 - val_accuracy: 0.9070\n","Epoch 19/100\n","6/6 [==============================] - 0s 14ms/step - loss: 659.8406 - accuracy: 0.9197 - val_loss: 410.9989 - val_accuracy: 0.9070\n","Epoch 20/100\n","6/6 [==============================] - 0s 14ms/step - loss: 415.5928 - accuracy: 0.8569 - val_loss: 279.0157 - val_accuracy: 0.9128\n","Epoch 21/100\n","6/6 [==============================] - 0s 11ms/step - loss: 427.1604 - accuracy: 0.9212 - val_loss: 201.2246 - val_accuracy: 0.9244\n","Epoch 22/100\n","6/6 [==============================] - 0s 11ms/step - loss: 311.8899 - accuracy: 0.8730 - val_loss: 167.5146 - val_accuracy: 0.9244\n","Epoch 23/100\n","6/6 [==============================] - 0s 11ms/step - loss: 220.6859 - accuracy: 0.8920 - val_loss: 134.5319 - val_accuracy: 0.9302\n","Epoch 24/100\n","6/6 [==============================] - 0s 13ms/step - loss: 179.1371 - accuracy: 0.8920 - val_loss: 195.2740 - val_accuracy: 0.7616\n","Epoch 25/100\n","6/6 [==============================] - 0s 11ms/step - loss: 147.5462 - accuracy: 0.8788 - val_loss: 64.6684 - val_accuracy: 0.9360\n","Epoch 26/100\n","6/6 [==============================] - 0s 14ms/step - loss: 111.8153 - accuracy: 0.8920 - val_loss: 82.5856 - val_accuracy: 0.9302\n","Epoch 27/100\n","6/6 [==============================] - 0s 14ms/step - loss: 76.2791 - accuracy: 0.8934 - val_loss: 60.9325 - val_accuracy: 0.9360\n","Epoch 28/100\n","6/6 [==============================] - 0s 15ms/step - loss: 58.7071 - accuracy: 0.9022 - val_loss: 228.1466 - val_accuracy: 0.9128\n","Epoch 29/100\n","6/6 [==============================] - 0s 11ms/step - loss: 172.9380 - accuracy: 0.9226 - val_loss: 74.0816 - val_accuracy: 0.9186\n","Epoch 30/100\n","6/6 [==============================] - 0s 11ms/step - loss: 218.1690 - accuracy: 0.8569 - val_loss: 454.3047 - val_accuracy: 0.9070\n","Epoch 31/100\n","6/6 [==============================] - 0s 11ms/step - loss: 301.7385 - accuracy: 0.9197 - val_loss: 171.2915 - val_accuracy: 0.9186\n","Epoch 32/100\n","6/6 [==============================] - 0s 15ms/step - loss: 172.5220 - accuracy: 0.8715 - val_loss: 252.1915 - val_accuracy: 0.9244\n","Epoch 33/100\n","6/6 [==============================] - 0s 12ms/step - loss: 150.5655 - accuracy: 0.9080 - val_loss: 135.6727 - val_accuracy: 0.9070\n","Epoch 34/100\n","6/6 [==============================] - 0s 11ms/step - loss: 81.5701 - accuracy: 0.9212 - val_loss: 349.0207 - val_accuracy: 0.7093\n","Epoch 35/100\n","6/6 [==============================] - 0s 12ms/step - loss: 224.5821 - accuracy: 0.8788 - val_loss: 216.3557 - val_accuracy: 0.9244\n","Epoch 36/100\n","6/6 [==============================] - 0s 14ms/step - loss: 80.8277 - accuracy: 0.9095 - val_loss: 78.0453 - val_accuracy: 0.9186\n","Epoch 37/100\n","6/6 [==============================] - 0s 13ms/step - loss: 35.3913 - accuracy: 0.9212 - val_loss: 38.1824 - val_accuracy: 0.9186\n","Epoch 38/100\n","6/6 [==============================] - 0s 12ms/step - loss: 30.8153 - accuracy: 0.9080 - val_loss: 69.8711 - val_accuracy: 0.9360\n","Epoch 39/100\n","6/6 [==============================] - 0s 14ms/step - loss: 34.9925 - accuracy: 0.9095 - val_loss: 29.6877 - val_accuracy: 0.9419\n","Epoch 40/100\n","6/6 [==============================] - 0s 16ms/step - loss: 19.5928 - accuracy: 0.9226 - val_loss: 30.5751 - val_accuracy: 0.9419\n","Epoch 41/100\n","6/6 [==============================] - 0s 14ms/step - loss: 29.5376 - accuracy: 0.9095 - val_loss: 38.9309 - val_accuracy: 0.9302\n","Epoch 42/100\n","6/6 [==============================] - 0s 13ms/step - loss: 31.0598 - accuracy: 0.9226 - val_loss: 36.0259 - val_accuracy: 0.9128\n","Epoch 43/100\n","6/6 [==============================] - 0s 13ms/step - loss: 29.9717 - accuracy: 0.9241 - val_loss: 127.9936 - val_accuracy: 0.9302\n","Epoch 44/100\n","6/6 [==============================] - 0s 14ms/step - loss: 86.2752 - accuracy: 0.8993 - val_loss: 43.9557 - val_accuracy: 0.9419\n","Epoch 45/100\n","6/6 [==============================] - 0s 11ms/step - loss: 18.9623 - accuracy: 0.9270 - val_loss: 42.8676 - val_accuracy: 0.9360\n","Epoch 46/100\n","6/6 [==============================] - 0s 12ms/step - loss: 23.1248 - accuracy: 0.9299 - val_loss: 30.5871 - val_accuracy: 0.9419\n","Epoch 47/100\n","6/6 [==============================] - 0s 15ms/step - loss: 100.8674 - accuracy: 0.9080 - val_loss: 285.4424 - val_accuracy: 0.9244\n","Epoch 48/100\n","6/6 [==============================] - 0s 12ms/step - loss: 145.9260 - accuracy: 0.9109 - val_loss: 59.8198 - val_accuracy: 0.9244\n","Epoch 49/100\n","6/6 [==============================] - 0s 11ms/step - loss: 188.5690 - accuracy: 0.9212 - val_loss: 199.3150 - val_accuracy: 0.9186\n","Epoch 50/100\n","6/6 [==============================] - 0s 19ms/step - loss: 114.7629 - accuracy: 0.8701 - val_loss: 177.3071 - val_accuracy: 0.9186\n","Epoch 51/100\n","6/6 [==============================] - 0s 36ms/step - loss: 78.3560 - accuracy: 0.9095 - val_loss: 48.9313 - val_accuracy: 0.9244\n","Epoch 52/100\n","6/6 [==============================] - 0s 27ms/step - loss: 56.1469 - accuracy: 0.9153 - val_loss: 76.8599 - val_accuracy: 0.9360\n","Epoch 53/100\n","6/6 [==============================] - 0s 18ms/step - loss: 114.8741 - accuracy: 0.9212 - val_loss: 62.2026 - val_accuracy: 0.8605\n","Epoch 54/100\n","6/6 [==============================] - 0s 26ms/step - loss: 31.4596 - accuracy: 0.9212 - val_loss: 58.4794 - val_accuracy: 0.9244\n","Epoch 55/100\n","6/6 [==============================] - 0s 20ms/step - loss: 68.0014 - accuracy: 0.9066 - val_loss: 165.0583 - val_accuracy: 0.9244\n","Epoch 56/100\n","6/6 [==============================] - 0s 28ms/step - loss: 87.9586 - accuracy: 0.8993 - val_loss: 95.3166 - val_accuracy: 0.9419\n","Epoch 57/100\n","6/6 [==============================] - 0s 29ms/step - loss: 50.7706 - accuracy: 0.9036 - val_loss: 175.2081 - val_accuracy: 0.9244\n","Epoch 58/100\n","6/6 [==============================] - 0s 27ms/step - loss: 136.5697 - accuracy: 0.9285 - val_loss: 112.1867 - val_accuracy: 0.7849\n","Epoch 59/100\n","6/6 [==============================] - 0s 31ms/step - loss: 80.2046 - accuracy: 0.9022 - val_loss: 48.6488 - val_accuracy: 0.9128\n","Epoch 60/100\n","6/6 [==============================] - 0s 22ms/step - loss: 73.2425 - accuracy: 0.9022 - val_loss: 92.7293 - val_accuracy: 0.9360\n","Epoch 61/100\n","6/6 [==============================] - 0s 32ms/step - loss: 40.2541 - accuracy: 0.9226 - val_loss: 66.6500 - val_accuracy: 0.9302\n","Epoch 62/100\n","6/6 [==============================] - 0s 16ms/step - loss: 32.3808 - accuracy: 0.9299 - val_loss: 56.4466 - val_accuracy: 0.9419\n","Epoch 63/100\n","6/6 [==============================] - 0s 40ms/step - loss: 26.3321 - accuracy: 0.9168 - val_loss: 10.8335 - val_accuracy: 0.9244\n","Epoch 64/100\n","6/6 [==============================] - 0s 41ms/step - loss: 23.8018 - accuracy: 0.9153 - val_loss: 17.1697 - val_accuracy: 0.9070\n","Epoch 65/100\n","6/6 [==============================] - 0s 29ms/step - loss: 57.9647 - accuracy: 0.9168 - val_loss: 237.4733 - val_accuracy: 0.7035\n","Epoch 66/100\n","6/6 [==============================] - 0s 50ms/step - loss: 150.9183 - accuracy: 0.8832 - val_loss: 147.6738 - val_accuracy: 0.9302\n","Epoch 67/100\n","6/6 [==============================] - 0s 48ms/step - loss: 116.3573 - accuracy: 0.8759 - val_loss: 284.9334 - val_accuracy: 0.9244\n","Epoch 68/100\n","6/6 [==============================] - 0s 25ms/step - loss: 151.1222 - accuracy: 0.9080 - val_loss: 77.3320 - val_accuracy: 0.9186\n","Epoch 69/100\n","6/6 [==============================] - 0s 22ms/step - loss: 144.9473 - accuracy: 0.9285 - val_loss: 182.2395 - val_accuracy: 0.9302\n","Epoch 70/100\n","6/6 [==============================] - 0s 36ms/step - loss: 98.5471 - accuracy: 0.8920 - val_loss: 192.5302 - val_accuracy: 0.9244\n","Epoch 71/100\n","6/6 [==============================] - 0s 20ms/step - loss: 99.8851 - accuracy: 0.9270 - val_loss: 214.9465 - val_accuracy: 0.7442\n","Epoch 72/100\n","6/6 [==============================] - 0s 35ms/step - loss: 121.0670 - accuracy: 0.8847 - val_loss: 138.5188 - val_accuracy: 0.9360\n","Epoch 73/100\n","6/6 [==============================] - 0s 17ms/step - loss: 55.1150 - accuracy: 0.9226 - val_loss: 72.7803 - val_accuracy: 0.9244\n","Epoch 74/100\n","6/6 [==============================] - 0s 23ms/step - loss: 36.4838 - accuracy: 0.9270 - val_loss: 156.9225 - val_accuracy: 0.9302\n","Epoch 75/100\n","6/6 [==============================] - 0s 20ms/step - loss: 287.4717 - accuracy: 0.9241 - val_loss: 360.5912 - val_accuracy: 0.9244\n","Epoch 76/100\n","6/6 [==============================] - 0s 19ms/step - loss: 189.1452 - accuracy: 0.8861 - val_loss: 160.8970 - val_accuracy: 0.9302\n","Epoch 77/100\n","6/6 [==============================] - 0s 17ms/step - loss: 164.9073 - accuracy: 0.9255 - val_loss: 43.8942 - val_accuracy: 0.9302\n","Epoch 78/100\n","6/6 [==============================] - 0s 17ms/step - loss: 133.5087 - accuracy: 0.8847 - val_loss: 213.3996 - val_accuracy: 0.9244\n","Epoch 79/100\n","6/6 [==============================] - 0s 18ms/step - loss: 101.7378 - accuracy: 0.9007 - val_loss: 124.2579 - val_accuracy: 0.9477\n","Epoch 80/100\n","6/6 [==============================] - 0s 32ms/step - loss: 64.3525 - accuracy: 0.9168 - val_loss: 57.3992 - val_accuracy: 0.9302\n","Epoch 81/100\n","6/6 [==============================] - 0s 18ms/step - loss: 102.2380 - accuracy: 0.9270 - val_loss: 52.7719 - val_accuracy: 0.9012\n","Epoch 82/100\n","6/6 [==============================] - 0s 20ms/step - loss: 62.3271 - accuracy: 0.9109 - val_loss: 26.9457 - val_accuracy: 0.9477\n","Epoch 83/100\n","6/6 [==============================] - 0s 14ms/step - loss: 80.8287 - accuracy: 0.8993 - val_loss: 187.1618 - val_accuracy: 0.9302\n","Epoch 84/100\n","6/6 [==============================] - 0s 17ms/step - loss: 72.5750 - accuracy: 0.9109 - val_loss: 122.0144 - val_accuracy: 0.9360\n","Epoch 85/100\n","6/6 [==============================] - 0s 18ms/step - loss: 72.6578 - accuracy: 0.9168 - val_loss: 32.0256 - val_accuracy: 0.9302\n","Epoch 86/100\n","6/6 [==============================] - 0s 17ms/step - loss: 26.4636 - accuracy: 0.9314 - val_loss: 17.3309 - val_accuracy: 0.9477\n","Epoch 87/100\n","6/6 [==============================] - 0s 14ms/step - loss: 23.5152 - accuracy: 0.9416 - val_loss: 93.8940 - val_accuracy: 0.8198\n","Epoch 88/100\n","6/6 [==============================] - 0s 18ms/step - loss: 47.6070 - accuracy: 0.9182 - val_loss: 48.8337 - val_accuracy: 0.9360\n","Epoch 89/100\n","6/6 [==============================] - 0s 17ms/step - loss: 16.7324 - accuracy: 0.9489 - val_loss: 38.2271 - val_accuracy: 0.9360\n","Epoch 90/100\n","6/6 [==============================] - 0s 17ms/step - loss: 19.2713 - accuracy: 0.9445 - val_loss: 43.3842 - val_accuracy: 0.9360\n","Epoch 91/100\n","6/6 [==============================] - 0s 28ms/step - loss: 14.7264 - accuracy: 0.9445 - val_loss: 12.0013 - val_accuracy: 0.9360\n","Epoch 92/100\n","6/6 [==============================] - 0s 21ms/step - loss: 21.3415 - accuracy: 0.9372 - val_loss: 22.8083 - val_accuracy: 0.9302\n","Epoch 93/100\n","6/6 [==============================] - 0s 38ms/step - loss: 20.4315 - accuracy: 0.9358 - val_loss: 59.1501 - val_accuracy: 0.9360\n","Epoch 94/100\n","6/6 [==============================] - 0s 31ms/step - loss: 33.7524 - accuracy: 0.9372 - val_loss: 46.2058 - val_accuracy: 0.9360\n","Epoch 95/100\n","6/6 [==============================] - 0s 39ms/step - loss: 41.4578 - accuracy: 0.9182 - val_loss: 114.6358 - val_accuracy: 0.9360\n","Epoch 96/100\n","6/6 [==============================] - 0s 27ms/step - loss: 71.2597 - accuracy: 0.9066 - val_loss: 249.4836 - val_accuracy: 0.9244\n","Epoch 97/100\n","6/6 [==============================] - 0s 45ms/step - loss: 303.7236 - accuracy: 0.9270 - val_loss: 192.3739 - val_accuracy: 0.9302\n","Epoch 98/100\n","6/6 [==============================] - 0s 36ms/step - loss: 70.8338 - accuracy: 0.9036 - val_loss: 263.8217 - val_accuracy: 0.9244\n","Epoch 99/100\n","6/6 [==============================] - 0s 25ms/step - loss: 162.0397 - accuracy: 0.9226 - val_loss: 49.7657 - val_accuracy: 0.9186\n","Epoch 100/100\n","6/6 [==============================] - 0s 28ms/step - loss: 77.3954 - accuracy: 0.9285 - val_loss: 58.8829 - val_accuracy: 0.9186\n","2/2 [==============================] - 0s 14ms/step - loss: 96.1763 - accuracy: 0.8791\n","Test loss: 96.1763, Test accuracy: 0.8791\n","7/7 [==============================] - 0s 5ms/step\n","Accuracy: 0.8791\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      Benign       1.00      0.87      0.93       201\n","   Malicious       0.35      1.00      0.52        14\n","\n","    accuracy                           0.88       215\n","   macro avg       0.68      0.94      0.72       215\n","weighted avg       0.96      0.88      0.90       215\n","\n","Confusion Matrix:\n","[[175  26]\n"," [  0  14]]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Load the dataset\n","data = pd.read_csv('/content/sample_data/5gnidd.csv')\n","# Drop unnecessary columns\n","unnecessary_columns = ['Unnamed: 0', 'RunTime', 'Min', 'Max', 'sTos', 'dTos', 'sDSb', 'dDSb', 'sHops', 'dHops', 'SrcWin',\n","                       'DstWin', 'sVid', 'dVid', 'SrcTCPBase', 'DstTCPBase', 'TcpRtt', 'SynAck', 'AckDat']\n","data = data.drop(unnecessary_columns, axis=1)\n","\n","# Drop any rows with missing values (NaNs) if present\n","data = data.dropna()\n","\n","# Separate features (X) and labels (y)\n","X = data.drop(['Label', 'Attack Type', 'Attack Tool'], axis=1)\n","y = data['Label']\n","\n","# Convert categorical columns to numerical using one-hot encoding\n","categorical_cols = ['Proto', 'Cause', 'State']\n","X = pd.get_dummies(X, columns=categorical_cols)\n","\n","# Convert the dataframe to a NumPy array\n","X = X.to_numpy()\n","\n","# Convert labels to numerical values\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(y)\n","\n","# Convert target labels to one-hot encoding\n","num_classes = len(label_encoder.classes_)\n","y = tf.keras.utils.to_categorical(y, num_classes)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(num_classes, activation='softmax')\n","])\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","batch_size = 128\n","epochs = 100\n","history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n","\n","# Evaluate the model on the test data\n","loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size)\n","print(f'Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}')\n","\n","# Make predictions on the test data\n","y_pred = model.predict(X_test)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_test_classes = np.argmax(y_test, axis=1)\n","\n","# Convert predicted labels back to original labels\n","y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n","y_test_labels = label_encoder.inverse_transform(y_test_classes)\n","\n","# Calculate accuracy and other metrics\n","accuracy = accuracy_score(y_test_labels, y_pred_labels)\n","print(f'Accuracy: {accuracy:.4f}')\n","\n","# Generate a classification report\n","report = classification_report(y_test_labels, y_pred_labels)\n","print('Classification Report:')\n","print(report)\n","\n","# Generate a confusion matrix\n","confusion = confusion_matrix(y_test_labels, y_pred_labels)\n","print('Confusion Matrix:')\n","print(confusion)\n"]}]}