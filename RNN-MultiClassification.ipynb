{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP7Y9TX+cqg76ILsUe3iNGD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rS5iQ0mMpw3","executionInfo":{"status":"ok","timestamp":1694392561504,"user_tz":-330,"elapsed":91759,"user":{"displayName":"Krishna Uprit","userId":"12130931885403965088"}},"outputId":"4c33c77b-df20-474f-8b4b-ecf976a72a28"},"outputs":[{"output_type":"stream","name":"stdout","text":["   Unnamed: 0  Seq       Dur   RunTime      Mean       Sum       Min  \\\n","0           0    1  0.000000  0.000000  0.000000  0.000000  0.000000   \n","1           1    2  0.000000  0.000000  0.000000  0.000000  0.000000   \n","2           2    3  4.998020  4.998020  4.998020  4.998020  4.998020   \n","3           3    4  4.998037  4.998037  4.998037  4.998037  4.998037   \n","4           4    5  4.999453  4.999453  4.999453  4.999453  4.999453   \n","\n","        Max Proto  sTos  ...  sVid dVid SrcTCPBase  DstTCPBase  TcpRtt  \\\n","0  0.000000  icmp   0.0  ...   NaN  NaN        NaN         NaN     0.0   \n","1  0.000000  icmp   0.0  ...   NaN  NaN        NaN         NaN     0.0   \n","2  4.998020   udp   0.0  ...   NaN  NaN        NaN         NaN     0.0   \n","3  4.998037   udp   0.0  ...   NaN  NaN        NaN         NaN     0.0   \n","4  4.999453   udp   0.0  ...   NaN  NaN        NaN         NaN     0.0   \n","\n","   SynAck  AckDat   Label  Attack Type  Attack Tool  \n","0     0.0     0.0  Benign       Benign       Benign  \n","1     0.0     0.0  Benign       Benign       Benign  \n","2     0.0     0.0  Benign       Benign       Benign  \n","3     0.0     0.0  Benign       Benign       Benign  \n","4     0.0     0.0  Benign       Benign       Benign  \n","\n","[5 rows x 52 columns]\n","\n","Number of columns before dropping: 52\n","Unique columns before dropping:\n","['Unnamed: 0', 'Seq', 'Dur', 'RunTime', 'Mean', 'Sum', 'Min', 'Max', 'Proto', 'sTos', 'dTos', 'sDSb', 'dDSb', 'sTtl', 'dTtl', 'sHops', 'dHops', 'Cause', 'TotPkts', 'SrcPkts', 'DstPkts', 'TotBytes', 'SrcBytes', 'DstBytes', 'Offset', 'sMeanPktSz', 'dMeanPktSz', 'Load', 'SrcLoad', 'DstLoad', 'Loss', 'SrcLoss', 'DstLoss', 'pLoss', 'SrcGap', 'DstGap', 'Rate', 'SrcRate', 'DstRate', 'State', 'SrcWin', 'DstWin', 'sVid', 'dVid', 'SrcTCPBase', 'DstTCPBase', 'TcpRtt', 'SynAck', 'AckDat', 'Label', 'Attack Type', 'Attack Tool']\n","\n","Number of columns after dropping: 33\n","Unique columns after dropping:\n","['Seq', 'Dur', 'Mean', 'Sum', 'Proto', 'sTtl', 'dTtl', 'Cause', 'TotPkts', 'SrcPkts', 'DstPkts', 'TotBytes', 'SrcBytes', 'DstBytes', 'Offset', 'sMeanPktSz', 'dMeanPktSz', 'Load', 'SrcLoad', 'DstLoad', 'Loss', 'SrcLoss', 'DstLoss', 'pLoss', 'SrcGap', 'DstGap', 'Rate', 'SrcRate', 'DstRate', 'State', 'Label', 'Attack Type', 'Attack Tool']\n","        Seq       Dur      Mean       Sum Proto  sTtl  dTtl   Cause  TotPkts  \\\n","23       20  0.124988  0.124988  0.124988   tcp  64.0  53.0   Start     10.0   \n","47       40  0.001938  0.001938  0.001938   tcp  50.0  59.0   Start      2.0   \n","56       45  0.014995  0.014995  0.014995   tcp  63.0  59.0   Start      3.0   \n","58       47  0.015981  0.015981  0.015981   tcp  63.0  59.0   Start      3.0   \n","68       57  0.001547  0.001547  0.001547   tcp  45.0  59.0   Start      2.0   \n","...     ...       ...       ...       ...   ...   ...   ...     ...      ...   \n","9166   8595  0.017152  0.017152  0.017152   tcp  63.0  59.0   Start      3.0   \n","9191   8618  0.002040  0.002040  0.002040   tcp  58.0  59.0   Start      2.0   \n","9390   8814  0.001695  0.001695  0.001695   tcp  37.0  59.0   Start      2.0   \n","9626   8551  0.014092  0.014092  0.014092   tcp  64.0  63.0  Status      4.0   \n","10148  9571  0.001932  0.001932  0.001932   tcp  43.0  59.0   Start      2.0   \n","\n","       SrcPkts  ...  pLoss  SrcGap  DstGap        Rate     SrcRate    DstRate  \\\n","23         5.0  ...    0.0     0.0     0.0   72.006912   32.003075  32.003075   \n","47         1.0  ...    0.0     0.0     0.0  515.995850    0.000000   0.000000   \n","56         2.0  ...    0.0     0.0     0.0  133.377792   66.688896   0.000000   \n","58         2.0  ...    0.0     0.0     0.0  125.148613   62.574306   0.000000   \n","68         1.0  ...    0.0     0.0     0.0  646.412415    0.000000   0.000000   \n","...        ...  ...    ...     ...     ...         ...         ...        ...   \n","9166       2.0  ...    0.0     0.0     0.0  116.604477   58.302238   0.000000   \n","9191       1.0  ...    0.0     0.0     0.0  490.196106    0.000000   0.000000   \n","9390       1.0  ...    0.0     0.0     0.0  589.970520    0.000000   0.000000   \n","9626       3.0  ...    0.0     0.0     0.0  212.886734  141.924500   0.000000   \n","10148      1.0  ...    0.0     0.0     0.0  517.598328    0.000000   0.000000   \n","\n","       State      Label  Attack Type  Attack Tool  \n","23       CON     Benign       Benign       Benign  \n","47       RST  Malicious      SYNScan         Nmap  \n","56       RST  Malicious      SYNScan         Nmap  \n","58       RST  Malicious      SYNScan         Nmap  \n","68       RST  Malicious      SYNScan         Nmap  \n","...      ...        ...          ...          ...  \n","9166     RST  Malicious      SYNScan         Nmap  \n","9191     RST  Malicious      SYNScan         Nmap  \n","9390     RST  Malicious      SYNScan         Nmap  \n","9626     FIN     Benign       Benign       Benign  \n","10148    RST  Malicious      SYNScan         Nmap  \n","\n","[98 rows x 33 columns]\n","\n","0\n","\n","(98, 33)\n","    Seq       Dur      Mean       Sum Proto  sTtl  dTtl  Cause  TotPkts  \\\n","23   20  0.124988  0.124988  0.124988   tcp  64.0  53.0  Start     10.0   \n","47   40  0.001938  0.001938  0.001938   tcp  50.0  59.0  Start      2.0   \n","56   45  0.014995  0.014995  0.014995   tcp  63.0  59.0  Start      3.0   \n","58   47  0.015981  0.015981  0.015981   tcp  63.0  59.0  Start      3.0   \n","68   57  0.001547  0.001547  0.001547   tcp  45.0  59.0  Start      2.0   \n","\n","    SrcPkts  ...  pLoss  SrcGap  DstGap        Rate    SrcRate    DstRate  \\\n","23      5.0  ...    0.0     0.0     0.0   72.006912  32.003075  32.003075   \n","47      1.0  ...    0.0     0.0     0.0  515.995850   0.000000   0.000000   \n","56      2.0  ...    0.0     0.0     0.0  133.377792  66.688896   0.000000   \n","58      2.0  ...    0.0     0.0     0.0  125.148613  62.574306   0.000000   \n","68      1.0  ...    0.0     0.0     0.0  646.412415   0.000000   0.000000   \n","\n","    State      Label  Attack Type  Attack Tool  \n","23    CON     Benign       Benign       Benign  \n","47    RST  Malicious      SYNScan         Nmap  \n","56    RST  Malicious      SYNScan         Nmap  \n","58    RST  Malicious      SYNScan         Nmap  \n","68    RST  Malicious      SYNScan         Nmap  \n","\n","[5 rows x 33 columns]\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [19 22 23 27] are constant.\n","  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n","  f = msb / msw\n"]},{"output_type":"stream","name":"stdout","text":["Observed columns:\n","['Seq', 'Dur', 'Mean', 'Sum', 'sTtl', 'dTtl', 'TotPkts', 'SrcPkts', 'DstPkts', 'TotBytes', 'SrcBytes', 'DstBytes', 'Offset', 'sMeanPktSz', 'dMeanPktSz', 'Load', 'SrcLoad', 'DstLoad', 'Loss', 'SrcLoss', 'DstLoss', 'pLoss', 'SrcGap', 'DstGap', 'Rate', 'SrcRate', 'DstRate', 'Proto_tcp', 'Cause_Start', 'Cause_Status', 'State_CON', 'State_FIN', 'State_RST']\n","Selected Features:\n","Index(['sTtl', 'TotPkts', 'SrcPkts', 'DstPkts', 'SrcBytes', 'sMeanPktSz',\n","       'Cause_Start', 'Cause_Status', 'State_CON', 'State_RST'],\n","      dtype='object')\n","Encoded Labels:  [[1. 0.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [0. 1.]\n"," [1. 0.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [1. 0.]\n"," [0. 1.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [0. 1.]\n"," [0. 1.]\n"," [1. 0.]\n"," [1. 0.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [0. 1.]\n"," [1. 0.]\n"," [0. 1.]]\n","\n","Epoch 1/500\n","1/1 [==============================] - 11s 11s/step - loss: 0.6833 - accuracy: 0.6596 - val_loss: 0.6557 - val_accuracy: 0.5714\n","Epoch 2/500\n","1/1 [==============================] - 0s 75ms/step - loss: 0.6181 - accuracy: 0.6596 - val_loss: 0.6463 - val_accuracy: 0.5714\n","Epoch 3/500\n","1/1 [==============================] - 0s 80ms/step - loss: 0.5874 - accuracy: 0.6596 - val_loss: 0.6435 - val_accuracy: 0.5714\n","Epoch 4/500\n","1/1 [==============================] - 0s 89ms/step - loss: 0.5726 - accuracy: 0.6596 - val_loss: 0.6347 - val_accuracy: 0.5714\n","Epoch 5/500\n","1/1 [==============================] - 0s 71ms/step - loss: 0.5601 - accuracy: 0.6596 - val_loss: 0.6171 - val_accuracy: 0.5714\n","Epoch 6/500\n","1/1 [==============================] - 0s 108ms/step - loss: 0.5455 - accuracy: 0.6596 - val_loss: 0.5956 - val_accuracy: 0.5714\n","Epoch 7/500\n","1/1 [==============================] - 0s 78ms/step - loss: 0.5306 - accuracy: 0.6596 - val_loss: 0.5745 - val_accuracy: 0.5714\n","Epoch 8/500\n","1/1 [==============================] - 0s 78ms/step - loss: 0.5198 - accuracy: 0.6596 - val_loss: 0.5520 - val_accuracy: 0.7619\n","Epoch 9/500\n","1/1 [==============================] - 0s 137ms/step - loss: 0.5049 - accuracy: 0.8085 - val_loss: 0.5313 - val_accuracy: 0.7143\n","Epoch 10/500\n","1/1 [==============================] - 0s 81ms/step - loss: 0.4885 - accuracy: 0.7872 - val_loss: 0.5100 - val_accuracy: 0.7143\n","Epoch 11/500\n","1/1 [==============================] - 0s 67ms/step - loss: 0.4691 - accuracy: 0.7660 - val_loss: 0.4933 - val_accuracy: 0.7143\n","Epoch 12/500\n","1/1 [==============================] - 0s 87ms/step - loss: 0.4506 - accuracy: 0.7660 - val_loss: 0.4826 - val_accuracy: 0.7143\n","Epoch 13/500\n","1/1 [==============================] - 0s 94ms/step - loss: 0.4361 - accuracy: 0.7660 - val_loss: 0.4690 - val_accuracy: 0.7143\n","Epoch 14/500\n","1/1 [==============================] - 0s 81ms/step - loss: 0.4221 - accuracy: 0.7447 - val_loss: 0.4475 - val_accuracy: 0.7143\n","Epoch 15/500\n","1/1 [==============================] - 0s 156ms/step - loss: 0.4064 - accuracy: 0.7447 - val_loss: 0.4269 - val_accuracy: 0.7143\n","Epoch 16/500\n","1/1 [==============================] - 0s 83ms/step - loss: 0.3923 - accuracy: 0.7447 - val_loss: 0.3992 - val_accuracy: 0.8571\n","Epoch 17/500\n","1/1 [==============================] - 0s 66ms/step - loss: 0.3786 - accuracy: 0.7872 - val_loss: 0.3780 - val_accuracy: 0.8571\n","Epoch 18/500\n","1/1 [==============================] - 0s 71ms/step - loss: 0.3647 - accuracy: 0.8298 - val_loss: 0.3635 - val_accuracy: 0.9048\n","Epoch 19/500\n","1/1 [==============================] - 0s 66ms/step - loss: 0.3477 - accuracy: 0.8511 - val_loss: 0.3550 - val_accuracy: 0.8571\n","Epoch 20/500\n","1/1 [==============================] - 0s 87ms/step - loss: 0.3336 - accuracy: 0.8511 - val_loss: 0.3402 - val_accuracy: 0.9048\n","Epoch 21/500\n","1/1 [==============================] - 0s 53ms/step - loss: 0.3201 - accuracy: 0.8723 - val_loss: 0.3160 - val_accuracy: 0.9048\n","Epoch 22/500\n","1/1 [==============================] - 0s 95ms/step - loss: 0.3054 - accuracy: 0.8723 - val_loss: 0.2932 - val_accuracy: 0.9048\n","Epoch 23/500\n","1/1 [==============================] - 0s 103ms/step - loss: 0.2943 - accuracy: 0.8723 - val_loss: 0.2839 - val_accuracy: 0.9048\n","Epoch 24/500\n","1/1 [==============================] - 0s 82ms/step - loss: 0.2821 - accuracy: 0.8723 - val_loss: 0.2856 - val_accuracy: 0.9048\n","Epoch 25/500\n","1/1 [==============================] - 0s 131ms/step - loss: 0.2709 - accuracy: 0.8723 - val_loss: 0.2797 - val_accuracy: 0.9048\n","Epoch 26/500\n","1/1 [==============================] - 0s 117ms/step - loss: 0.2602 - accuracy: 0.8936 - val_loss: 0.2561 - val_accuracy: 0.9048\n","Epoch 27/500\n","1/1 [==============================] - 0s 143ms/step - loss: 0.2508 - accuracy: 0.8723 - val_loss: 0.2522 - val_accuracy: 0.9048\n","Epoch 28/500\n","1/1 [==============================] - 0s 175ms/step - loss: 0.2380 - accuracy: 0.8723 - val_loss: 0.2638 - val_accuracy: 0.9048\n","Epoch 29/500\n","1/1 [==============================] - 0s 163ms/step - loss: 0.2276 - accuracy: 0.9362 - val_loss: 0.2393 - val_accuracy: 0.9048\n","Epoch 30/500\n","1/1 [==============================] - 0s 187ms/step - loss: 0.2090 - accuracy: 0.9362 - val_loss: 0.2275 - val_accuracy: 0.9048\n","Epoch 31/500\n","1/1 [==============================] - 0s 120ms/step - loss: 0.1910 - accuracy: 0.9362 - val_loss: 0.2149 - val_accuracy: 0.9048\n","Epoch 32/500\n","1/1 [==============================] - 0s 133ms/step - loss: 0.1739 - accuracy: 0.9362 - val_loss: 0.1977 - val_accuracy: 0.9048\n","Epoch 33/500\n","1/1 [==============================] - 0s 125ms/step - loss: 0.1579 - accuracy: 0.9362 - val_loss: 0.2053 - val_accuracy: 0.9048\n","Epoch 34/500\n","1/1 [==============================] - 0s 89ms/step - loss: 0.1568 - accuracy: 0.9362 - val_loss: 0.2030 - val_accuracy: 0.9048\n","Epoch 35/500\n","1/1 [==============================] - 0s 125ms/step - loss: 0.1839 - accuracy: 0.8936 - val_loss: 0.1666 - val_accuracy: 0.9048\n","Epoch 36/500\n","1/1 [==============================] - 0s 137ms/step - loss: 0.1216 - accuracy: 0.9362 - val_loss: 0.2276 - val_accuracy: 1.0000\n","Epoch 37/500\n","1/1 [==============================] - 0s 194ms/step - loss: 0.1796 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9048\n","Epoch 38/500\n","1/1 [==============================] - 0s 107ms/step - loss: 0.1112 - accuracy: 0.9362 - val_loss: 0.1965 - val_accuracy: 0.9048\n","Epoch 39/500\n","1/1 [==============================] - 0s 172ms/step - loss: 0.1659 - accuracy: 0.9149 - val_loss: 0.1506 - val_accuracy: 0.9048\n","Epoch 40/500\n","1/1 [==============================] - 0s 156ms/step - loss: 0.1092 - accuracy: 0.9362 - val_loss: 0.1372 - val_accuracy: 1.0000\n","Epoch 41/500\n","1/1 [==============================] - 0s 70ms/step - loss: 0.1072 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 1.0000\n","Epoch 42/500\n","1/1 [==============================] - 0s 158ms/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9048\n","Epoch 43/500\n","1/1 [==============================] - 0s 58ms/step - loss: 0.0850 - accuracy: 0.9362 - val_loss: 0.1645 - val_accuracy: 0.9048\n","Epoch 44/500\n","1/1 [==============================] - 0s 50ms/step - loss: 0.1039 - accuracy: 0.9362 - val_loss: 0.1009 - val_accuracy: 0.9048\n","Epoch 45/500\n","1/1 [==============================] - 0s 76ms/step - loss: 0.0645 - accuracy: 0.9787 - val_loss: 0.1018 - val_accuracy: 1.0000\n","Epoch 46/500\n","1/1 [==============================] - 0s 156ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 1.0000\n","Epoch 47/500\n","1/1 [==============================] - 0s 151ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9048\n","Epoch 48/500\n","1/1 [==============================] - 0s 142ms/step - loss: 0.0568 - accuracy: 0.9574 - val_loss: 0.0542 - val_accuracy: 1.0000\n","Epoch 49/500\n","1/1 [==============================] - 0s 176ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 1.0000\n","Epoch 50/500\n","1/1 [==============================] - 0s 70ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 1.0000\n","Epoch 51/500\n","1/1 [==============================] - 0s 70ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 1.0000\n","Epoch 52/500\n","1/1 [==============================] - 0s 87ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 1.0000\n","Epoch 53/500\n","1/1 [==============================] - 0s 50ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n","Epoch 54/500\n","1/1 [==============================] - 0s 67ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n","Epoch 55/500\n","1/1 [==============================] - 0s 64ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n","Epoch 56/500\n","1/1 [==============================] - 0s 71ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n","Epoch 57/500\n","1/1 [==============================] - 0s 72ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n","Epoch 58/500\n","1/1 [==============================] - 0s 71ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n","Epoch 59/500\n","1/1 [==============================] - 0s 62ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n","Epoch 60/500\n","1/1 [==============================] - 0s 62ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n","Epoch 61/500\n","1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n","Epoch 62/500\n","1/1 [==============================] - 0s 68ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 63/500\n","1/1 [==============================] - 0s 98ms/step - loss: 8.7583e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 64/500\n","1/1 [==============================] - 0s 67ms/step - loss: 8.3775e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 65/500\n","1/1 [==============================] - 0s 109ms/step - loss: 8.5525e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 66/500\n","1/1 [==============================] - 0s 131ms/step - loss: 8.6698e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 67/500\n","1/1 [==============================] - 0s 85ms/step - loss: 8.8448e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n","Epoch 68/500\n","1/1 [==============================] - 0s 61ms/step - loss: 8.1666e-04 - accuracy: 1.0000 - val_loss: 9.2209e-04 - val_accuracy: 1.0000\n","Epoch 69/500\n","1/1 [==============================] - 0s 95ms/step - loss: 7.4981e-04 - accuracy: 1.0000 - val_loss: 8.1520e-04 - val_accuracy: 1.0000\n","Epoch 70/500\n","1/1 [==============================] - 0s 55ms/step - loss: 6.6335e-04 - accuracy: 1.0000 - val_loss: 7.0306e-04 - val_accuracy: 1.0000\n","Epoch 71/500\n","1/1 [==============================] - 0s 72ms/step - loss: 5.7228e-04 - accuracy: 1.0000 - val_loss: 5.9874e-04 - val_accuracy: 1.0000\n","Epoch 72/500\n","1/1 [==============================] - 0s 77ms/step - loss: 4.8816e-04 - accuracy: 1.0000 - val_loss: 5.1014e-04 - val_accuracy: 1.0000\n","Epoch 73/500\n","1/1 [==============================] - 0s 117ms/step - loss: 4.1646e-04 - accuracy: 1.0000 - val_loss: 4.3571e-04 - val_accuracy: 1.0000\n","Epoch 74/500\n","1/1 [==============================] - 0s 54ms/step - loss: 3.5749e-04 - accuracy: 1.0000 - val_loss: 3.7577e-04 - val_accuracy: 1.0000\n","Epoch 75/500\n","1/1 [==============================] - 0s 78ms/step - loss: 3.1097e-04 - accuracy: 1.0000 - val_loss: 3.2765e-04 - val_accuracy: 1.0000\n","Epoch 76/500\n","1/1 [==============================] - 0s 134ms/step - loss: 2.7451e-04 - accuracy: 1.0000 - val_loss: 2.8874e-04 - val_accuracy: 1.0000\n","Epoch 77/500\n","1/1 [==============================] - 0s 100ms/step - loss: 2.4676e-04 - accuracy: 1.0000 - val_loss: 2.5733e-04 - val_accuracy: 1.0000\n","Epoch 78/500\n","1/1 [==============================] - 0s 59ms/step - loss: 2.2669e-04 - accuracy: 1.0000 - val_loss: 2.3188e-04 - val_accuracy: 1.0000\n","Epoch 79/500\n","1/1 [==============================] - 0s 79ms/step - loss: 2.1332e-04 - accuracy: 1.0000 - val_loss: 2.1154e-04 - val_accuracy: 1.0000\n","Epoch 80/500\n","1/1 [==============================] - 0s 59ms/step - loss: 2.0587e-04 - accuracy: 1.0000 - val_loss: 1.9514e-04 - val_accuracy: 1.0000\n","Epoch 81/500\n","1/1 [==============================] - 0s 62ms/step - loss: 2.0262e-04 - accuracy: 1.0000 - val_loss: 1.8179e-04 - val_accuracy: 1.0000\n","Epoch 82/500\n","1/1 [==============================] - 0s 65ms/step - loss: 2.0172e-04 - accuracy: 1.0000 - val_loss: 1.7095e-04 - val_accuracy: 1.0000\n","Epoch 83/500\n","1/1 [==============================] - 0s 103ms/step - loss: 2.0063e-04 - accuracy: 1.0000 - val_loss: 1.6213e-04 - val_accuracy: 1.0000\n","Epoch 84/500\n","1/1 [==============================] - 0s 99ms/step - loss: 1.9704e-04 - accuracy: 1.0000 - val_loss: 1.5496e-04 - val_accuracy: 1.0000\n","Epoch 85/500\n","1/1 [==============================] - 0s 64ms/step - loss: 1.8984e-04 - accuracy: 1.0000 - val_loss: 1.4907e-04 - val_accuracy: 1.0000\n","Epoch 86/500\n","1/1 [==============================] - 0s 74ms/step - loss: 1.7942e-04 - accuracy: 1.0000 - val_loss: 1.4416e-04 - val_accuracy: 1.0000\n","Epoch 87/500\n","1/1 [==============================] - 0s 57ms/step - loss: 1.6735e-04 - accuracy: 1.0000 - val_loss: 1.4000e-04 - val_accuracy: 1.0000\n","Epoch 88/500\n","1/1 [==============================] - 0s 81ms/step - loss: 1.5532e-04 - accuracy: 1.0000 - val_loss: 1.3650e-04 - val_accuracy: 1.0000\n","Epoch 89/500\n","1/1 [==============================] - 0s 144ms/step - loss: 1.4450e-04 - accuracy: 1.0000 - val_loss: 1.3345e-04 - val_accuracy: 1.0000\n","Epoch 90/500\n","1/1 [==============================] - 0s 61ms/step - loss: 1.3547e-04 - accuracy: 1.0000 - val_loss: 1.3079e-04 - val_accuracy: 1.0000\n","Epoch 91/500\n","1/1 [==============================] - 0s 70ms/step - loss: 1.2814e-04 - accuracy: 1.0000 - val_loss: 1.2847e-04 - val_accuracy: 1.0000\n","Epoch 92/500\n","1/1 [==============================] - 0s 77ms/step - loss: 1.2232e-04 - accuracy: 1.0000 - val_loss: 1.2636e-04 - val_accuracy: 1.0000\n","Epoch 93/500\n","1/1 [==============================] - 0s 61ms/step - loss: 1.1769e-04 - accuracy: 1.0000 - val_loss: 1.2441e-04 - val_accuracy: 1.0000\n","Epoch 94/500\n","1/1 [==============================] - 0s 52ms/step - loss: 1.1399e-04 - accuracy: 1.0000 - val_loss: 1.2257e-04 - val_accuracy: 1.0000\n","Epoch 95/500\n","1/1 [==============================] - 0s 91ms/step - loss: 1.1094e-04 - accuracy: 1.0000 - val_loss: 1.2084e-04 - val_accuracy: 1.0000\n","Epoch 96/500\n","1/1 [==============================] - 0s 128ms/step - loss: 1.0843e-04 - accuracy: 1.0000 - val_loss: 1.1921e-04 - val_accuracy: 1.0000\n","Epoch 97/500\n","1/1 [==============================] - 0s 70ms/step - loss: 1.0630e-04 - accuracy: 1.0000 - val_loss: 1.1762e-04 - val_accuracy: 1.0000\n","Epoch 98/500\n","1/1 [==============================] - 0s 108ms/step - loss: 1.0444e-04 - accuracy: 1.0000 - val_loss: 1.1603e-04 - val_accuracy: 1.0000\n","Epoch 99/500\n","1/1 [==============================] - 0s 106ms/step - loss: 1.0274e-04 - accuracy: 1.0000 - val_loss: 1.1444e-04 - val_accuracy: 1.0000\n","Epoch 100/500\n","1/1 [==============================] - 0s 78ms/step - loss: 1.0118e-04 - accuracy: 1.0000 - val_loss: 1.1287e-04 - val_accuracy: 1.0000\n","Epoch 101/500\n","1/1 [==============================] - 0s 167ms/step - loss: 9.9696e-05 - accuracy: 1.0000 - val_loss: 1.1129e-04 - val_accuracy: 1.0000\n","Epoch 102/500\n","1/1 [==============================] - 0s 134ms/step - loss: 9.8263e-05 - accuracy: 1.0000 - val_loss: 1.0972e-04 - val_accuracy: 1.0000\n","Epoch 103/500\n","1/1 [==============================] - 0s 130ms/step - loss: 9.6850e-05 - accuracy: 1.0000 - val_loss: 1.0813e-04 - val_accuracy: 1.0000\n","Epoch 104/500\n","1/1 [==============================] - 0s 120ms/step - loss: 9.5438e-05 - accuracy: 1.0000 - val_loss: 1.0655e-04 - val_accuracy: 1.0000\n","Epoch 105/500\n","1/1 [==============================] - 0s 116ms/step - loss: 9.4031e-05 - accuracy: 1.0000 - val_loss: 1.0499e-04 - val_accuracy: 1.0000\n","Epoch 106/500\n","1/1 [==============================] - 0s 83ms/step - loss: 9.2628e-05 - accuracy: 1.0000 - val_loss: 1.0343e-04 - val_accuracy: 1.0000\n","Epoch 107/500\n","1/1 [==============================] - 0s 69ms/step - loss: 9.1231e-05 - accuracy: 1.0000 - val_loss: 1.0188e-04 - val_accuracy: 1.0000\n","Epoch 108/500\n","1/1 [==============================] - 0s 64ms/step - loss: 8.9834e-05 - accuracy: 1.0000 - val_loss: 1.0037e-04 - val_accuracy: 1.0000\n","Epoch 109/500\n","1/1 [==============================] - 0s 75ms/step - loss: 8.8462e-05 - accuracy: 1.0000 - val_loss: 9.8882e-05 - val_accuracy: 1.0000\n","Epoch 110/500\n","1/1 [==============================] - 0s 146ms/step - loss: 8.7101e-05 - accuracy: 1.0000 - val_loss: 9.7440e-05 - val_accuracy: 1.0000\n","Epoch 111/500\n","1/1 [==============================] - 0s 139ms/step - loss: 8.5780e-05 - accuracy: 1.0000 - val_loss: 9.6027e-05 - val_accuracy: 1.0000\n","Epoch 112/500\n","1/1 [==============================] - 0s 93ms/step - loss: 8.4481e-05 - accuracy: 1.0000 - val_loss: 9.4654e-05 - val_accuracy: 1.0000\n","Epoch 113/500\n","1/1 [==============================] - 0s 110ms/step - loss: 8.3221e-05 - accuracy: 1.0000 - val_loss: 9.3326e-05 - val_accuracy: 1.0000\n","Epoch 114/500\n","1/1 [==============================] - 0s 117ms/step - loss: 8.1999e-05 - accuracy: 1.0000 - val_loss: 9.2054e-05 - val_accuracy: 1.0000\n","Epoch 115/500\n","1/1 [==============================] - 0s 154ms/step - loss: 8.0797e-05 - accuracy: 1.0000 - val_loss: 9.0840e-05 - val_accuracy: 1.0000\n","Epoch 116/500\n","1/1 [==============================] - 0s 87ms/step - loss: 7.9651e-05 - accuracy: 1.0000 - val_loss: 8.9671e-05 - val_accuracy: 1.0000\n","Epoch 117/500\n","1/1 [==============================] - 0s 84ms/step - loss: 7.8540e-05 - accuracy: 1.0000 - val_loss: 8.8553e-05 - val_accuracy: 1.0000\n","Epoch 118/500\n","1/1 [==============================] - 0s 194ms/step - loss: 7.7483e-05 - accuracy: 1.0000 - val_loss: 8.7486e-05 - val_accuracy: 1.0000\n","Epoch 119/500\n","1/1 [==============================] - 0s 78ms/step - loss: 7.6481e-05 - accuracy: 1.0000 - val_loss: 8.6464e-05 - val_accuracy: 1.0000\n","Epoch 120/500\n","1/1 [==============================] - 0s 132ms/step - loss: 7.5525e-05 - accuracy: 1.0000 - val_loss: 8.5488e-05 - val_accuracy: 1.0000\n","Epoch 121/500\n","1/1 [==============================] - 0s 108ms/step - loss: 7.4607e-05 - accuracy: 1.0000 - val_loss: 8.4552e-05 - val_accuracy: 1.0000\n","Epoch 122/500\n","1/1 [==============================] - 0s 92ms/step - loss: 7.3727e-05 - accuracy: 1.0000 - val_loss: 8.3655e-05 - val_accuracy: 1.0000\n","Epoch 123/500\n","1/1 [==============================] - 0s 135ms/step - loss: 7.2883e-05 - accuracy: 1.0000 - val_loss: 8.2787e-05 - val_accuracy: 1.0000\n","Epoch 124/500\n","1/1 [==============================] - 0s 102ms/step - loss: 7.2074e-05 - accuracy: 1.0000 - val_loss: 8.1981e-05 - val_accuracy: 1.0000\n","Epoch 125/500\n","1/1 [==============================] - 0s 98ms/step - loss: 7.1296e-05 - accuracy: 1.0000 - val_loss: 8.1192e-05 - val_accuracy: 1.0000\n","Epoch 126/500\n","1/1 [==============================] - 0s 73ms/step - loss: 7.0553e-05 - accuracy: 1.0000 - val_loss: 8.0437e-05 - val_accuracy: 1.0000\n","Epoch 127/500\n","1/1 [==============================] - 0s 93ms/step - loss: 6.9827e-05 - accuracy: 1.0000 - val_loss: 7.9710e-05 - val_accuracy: 1.0000\n","Epoch 128/500\n","1/1 [==============================] - 0s 157ms/step - loss: 6.9117e-05 - accuracy: 1.0000 - val_loss: 7.9001e-05 - val_accuracy: 1.0000\n","Epoch 129/500\n","1/1 [==============================] - 0s 153ms/step - loss: 6.8440e-05 - accuracy: 1.0000 - val_loss: 7.8320e-05 - val_accuracy: 1.0000\n","Epoch 130/500\n","1/1 [==============================] - 0s 124ms/step - loss: 6.7771e-05 - accuracy: 1.0000 - val_loss: 7.7656e-05 - val_accuracy: 1.0000\n","Epoch 131/500\n","1/1 [==============================] - 0s 75ms/step - loss: 6.7122e-05 - accuracy: 1.0000 - val_loss: 7.7015e-05 - val_accuracy: 1.0000\n","Epoch 132/500\n","1/1 [==============================] - 0s 86ms/step - loss: 6.6483e-05 - accuracy: 1.0000 - val_loss: 7.6385e-05 - val_accuracy: 1.0000\n","Epoch 133/500\n","1/1 [==============================] - 0s 104ms/step - loss: 6.5866e-05 - accuracy: 1.0000 - val_loss: 7.5766e-05 - val_accuracy: 1.0000\n","Epoch 134/500\n","1/1 [==============================] - 0s 83ms/step - loss: 6.5250e-05 - accuracy: 1.0000 - val_loss: 7.5170e-05 - val_accuracy: 1.0000\n","Epoch 135/500\n","1/1 [==============================] - 0s 77ms/step - loss: 6.4631e-05 - accuracy: 1.0000 - val_loss: 7.4568e-05 - val_accuracy: 1.0000\n","Epoch 136/500\n","1/1 [==============================] - 0s 72ms/step - loss: 6.4033e-05 - accuracy: 1.0000 - val_loss: 7.3972e-05 - val_accuracy: 1.0000\n","Epoch 137/500\n","1/1 [==============================] - 0s 84ms/step - loss: 6.3440e-05 - accuracy: 1.0000 - val_loss: 7.3376e-05 - val_accuracy: 1.0000\n","Epoch 138/500\n","1/1 [==============================] - 0s 72ms/step - loss: 6.2846e-05 - accuracy: 1.0000 - val_loss: 7.2786e-05 - val_accuracy: 1.0000\n","Epoch 139/500\n","1/1 [==============================] - 0s 118ms/step - loss: 6.2281e-05 - accuracy: 1.0000 - val_loss: 7.2224e-05 - val_accuracy: 1.0000\n","Epoch 140/500\n","1/1 [==============================] - 0s 153ms/step - loss: 6.1710e-05 - accuracy: 1.0000 - val_loss: 7.1634e-05 - val_accuracy: 1.0000\n","Epoch 141/500\n","1/1 [==============================] - 0s 202ms/step - loss: 6.1140e-05 - accuracy: 1.0000 - val_loss: 7.1066e-05 - val_accuracy: 1.0000\n","Epoch 142/500\n","1/1 [==============================] - 0s 237ms/step - loss: 6.0577e-05 - accuracy: 1.0000 - val_loss: 7.0493e-05 - val_accuracy: 1.0000\n","Epoch 143/500\n","1/1 [==============================] - 0s 128ms/step - loss: 6.0024e-05 - accuracy: 1.0000 - val_loss: 6.9937e-05 - val_accuracy: 1.0000\n","Epoch 144/500\n","1/1 [==============================] - 0s 73ms/step - loss: 5.9478e-05 - accuracy: 1.0000 - val_loss: 6.9381e-05 - val_accuracy: 1.0000\n","Epoch 145/500\n","1/1 [==============================] - 0s 56ms/step - loss: 5.8931e-05 - accuracy: 1.0000 - val_loss: 6.8824e-05 - val_accuracy: 1.0000\n","Epoch 146/500\n","1/1 [==============================] - 0s 53ms/step - loss: 5.8398e-05 - accuracy: 1.0000 - val_loss: 6.8280e-05 - val_accuracy: 1.0000\n","Epoch 147/500\n","1/1 [==============================] - 0s 69ms/step - loss: 5.7881e-05 - accuracy: 1.0000 - val_loss: 6.7729e-05 - val_accuracy: 1.0000\n","Epoch 148/500\n","1/1 [==============================] - 0s 55ms/step - loss: 5.7353e-05 - accuracy: 1.0000 - val_loss: 6.7178e-05 - val_accuracy: 1.0000\n","Epoch 149/500\n","1/1 [==============================] - 0s 61ms/step - loss: 5.6841e-05 - accuracy: 1.0000 - val_loss: 6.6651e-05 - val_accuracy: 1.0000\n","Epoch 150/500\n","1/1 [==============================] - 0s 50ms/step - loss: 5.6326e-05 - accuracy: 1.0000 - val_loss: 6.6111e-05 - val_accuracy: 1.0000\n","Epoch 151/500\n","1/1 [==============================] - 0s 48ms/step - loss: 5.5824e-05 - accuracy: 1.0000 - val_loss: 6.5595e-05 - val_accuracy: 1.0000\n","Epoch 152/500\n","1/1 [==============================] - 0s 65ms/step - loss: 5.5335e-05 - accuracy: 1.0000 - val_loss: 6.5050e-05 - val_accuracy: 1.0000\n","Epoch 153/500\n","1/1 [==============================] - 0s 73ms/step - loss: 5.4843e-05 - accuracy: 1.0000 - val_loss: 6.4539e-05 - val_accuracy: 1.0000\n","Epoch 154/500\n","1/1 [==============================] - 0s 62ms/step - loss: 5.4358e-05 - accuracy: 1.0000 - val_loss: 6.4011e-05 - val_accuracy: 1.0000\n","Epoch 155/500\n","1/1 [==============================] - 0s 66ms/step - loss: 5.3892e-05 - accuracy: 1.0000 - val_loss: 6.3512e-05 - val_accuracy: 1.0000\n","Epoch 156/500\n","1/1 [==============================] - 0s 57ms/step - loss: 5.3415e-05 - accuracy: 1.0000 - val_loss: 6.3001e-05 - val_accuracy: 1.0000\n","Epoch 157/500\n","1/1 [==============================] - 0s 69ms/step - loss: 5.2956e-05 - accuracy: 1.0000 - val_loss: 6.2496e-05 - val_accuracy: 1.0000\n","Epoch 158/500\n","1/1 [==============================] - 0s 62ms/step - loss: 5.2494e-05 - accuracy: 1.0000 - val_loss: 6.2002e-05 - val_accuracy: 1.0000\n","Epoch 159/500\n","1/1 [==============================] - 0s 45ms/step - loss: 5.2035e-05 - accuracy: 1.0000 - val_loss: 6.1508e-05 - val_accuracy: 1.0000\n","Epoch 160/500\n","1/1 [==============================] - 0s 67ms/step - loss: 5.1584e-05 - accuracy: 1.0000 - val_loss: 6.1014e-05 - val_accuracy: 1.0000\n","Epoch 161/500\n","1/1 [==============================] - 0s 60ms/step - loss: 5.1145e-05 - accuracy: 1.0000 - val_loss: 6.0532e-05 - val_accuracy: 1.0000\n","Epoch 162/500\n","1/1 [==============================] - 0s 64ms/step - loss: 5.0706e-05 - accuracy: 1.0000 - val_loss: 6.0044e-05 - val_accuracy: 1.0000\n","Epoch 163/500\n","1/1 [==============================] - 0s 64ms/step - loss: 5.0273e-05 - accuracy: 1.0000 - val_loss: 5.9567e-05 - val_accuracy: 1.0000\n","Epoch 164/500\n","1/1 [==============================] - 0s 63ms/step - loss: 4.9839e-05 - accuracy: 1.0000 - val_loss: 5.9090e-05 - val_accuracy: 1.0000\n","Epoch 165/500\n","1/1 [==============================] - 0s 63ms/step - loss: 4.9410e-05 - accuracy: 1.0000 - val_loss: 5.8614e-05 - val_accuracy: 1.0000\n","Epoch 166/500\n","1/1 [==============================] - 0s 56ms/step - loss: 4.8982e-05 - accuracy: 1.0000 - val_loss: 5.8159e-05 - val_accuracy: 1.0000\n","Epoch 167/500\n","1/1 [==============================] - 0s 68ms/step - loss: 4.8566e-05 - accuracy: 1.0000 - val_loss: 5.7694e-05 - val_accuracy: 1.0000\n","Epoch 168/500\n","1/1 [==============================] - 0s 66ms/step - loss: 4.8153e-05 - accuracy: 1.0000 - val_loss: 5.7234e-05 - val_accuracy: 1.0000\n","Epoch 169/500\n","1/1 [==============================] - 0s 66ms/step - loss: 4.7742e-05 - accuracy: 1.0000 - val_loss: 5.6780e-05 - val_accuracy: 1.0000\n","Epoch 170/500\n","1/1 [==============================] - 0s 59ms/step - loss: 4.7346e-05 - accuracy: 1.0000 - val_loss: 5.6332e-05 - val_accuracy: 1.0000\n","Epoch 171/500\n","1/1 [==============================] - 0s 68ms/step - loss: 4.6940e-05 - accuracy: 1.0000 - val_loss: 5.5889e-05 - val_accuracy: 1.0000\n","Epoch 172/500\n","1/1 [==============================] - 0s 67ms/step - loss: 4.6542e-05 - accuracy: 1.0000 - val_loss: 5.5435e-05 - val_accuracy: 1.0000\n","Epoch 173/500\n","1/1 [==============================] - 0s 51ms/step - loss: 4.6136e-05 - accuracy: 1.0000 - val_loss: 5.4998e-05 - val_accuracy: 1.0000\n","Epoch 174/500\n","1/1 [==============================] - 0s 38ms/step - loss: 4.5743e-05 - accuracy: 1.0000 - val_loss: 5.4561e-05 - val_accuracy: 1.0000\n","Epoch 175/500\n","1/1 [==============================] - 0s 42ms/step - loss: 4.5360e-05 - accuracy: 1.0000 - val_loss: 5.4129e-05 - val_accuracy: 1.0000\n","Epoch 176/500\n","1/1 [==============================] - 0s 40ms/step - loss: 4.4972e-05 - accuracy: 1.0000 - val_loss: 5.3698e-05 - val_accuracy: 1.0000\n","Epoch 177/500\n","1/1 [==============================] - 0s 38ms/step - loss: 4.4589e-05 - accuracy: 1.0000 - val_loss: 5.3278e-05 - val_accuracy: 1.0000\n","Epoch 178/500\n","1/1 [==============================] - 0s 45ms/step - loss: 4.4212e-05 - accuracy: 1.0000 - val_loss: 5.2852e-05 - val_accuracy: 1.0000\n","Epoch 179/500\n","1/1 [==============================] - 0s 37ms/step - loss: 4.3839e-05 - accuracy: 1.0000 - val_loss: 5.2432e-05 - val_accuracy: 1.0000\n","Epoch 180/500\n","1/1 [==============================] - 0s 37ms/step - loss: 4.3458e-05 - accuracy: 1.0000 - val_loss: 5.2007e-05 - val_accuracy: 1.0000\n","Epoch 181/500\n","1/1 [==============================] - 0s 40ms/step - loss: 4.3096e-05 - accuracy: 1.0000 - val_loss: 5.1587e-05 - val_accuracy: 1.0000\n","Epoch 182/500\n","1/1 [==============================] - 0s 39ms/step - loss: 4.2728e-05 - accuracy: 1.0000 - val_loss: 5.1184e-05 - val_accuracy: 1.0000\n","Epoch 183/500\n","1/1 [==============================] - 0s 44ms/step - loss: 4.2368e-05 - accuracy: 1.0000 - val_loss: 5.0769e-05 - val_accuracy: 1.0000\n","Epoch 184/500\n","1/1 [==============================] - 0s 36ms/step - loss: 4.2010e-05 - accuracy: 1.0000 - val_loss: 5.0366e-05 - val_accuracy: 1.0000\n","Epoch 185/500\n","1/1 [==============================] - 0s 39ms/step - loss: 4.1650e-05 - accuracy: 1.0000 - val_loss: 4.9975e-05 - val_accuracy: 1.0000\n","Epoch 186/500\n","1/1 [==============================] - 0s 37ms/step - loss: 4.1308e-05 - accuracy: 1.0000 - val_loss: 4.9572e-05 - val_accuracy: 1.0000\n","Epoch 187/500\n","1/1 [==============================] - 0s 38ms/step - loss: 4.0953e-05 - accuracy: 1.0000 - val_loss: 4.9174e-05 - val_accuracy: 1.0000\n","Epoch 188/500\n","1/1 [==============================] - 0s 41ms/step - loss: 4.0608e-05 - accuracy: 1.0000 - val_loss: 4.8788e-05 - val_accuracy: 1.0000\n","Epoch 189/500\n","1/1 [==============================] - 0s 42ms/step - loss: 4.0255e-05 - accuracy: 1.0000 - val_loss: 4.8385e-05 - val_accuracy: 1.0000\n","Epoch 190/500\n","1/1 [==============================] - 0s 37ms/step - loss: 3.9910e-05 - accuracy: 1.0000 - val_loss: 4.7994e-05 - val_accuracy: 1.0000\n","Epoch 191/500\n","1/1 [==============================] - 0s 40ms/step - loss: 3.9578e-05 - accuracy: 1.0000 - val_loss: 4.7613e-05 - val_accuracy: 1.0000\n","Epoch 192/500\n","1/1 [==============================] - 0s 39ms/step - loss: 3.9236e-05 - accuracy: 1.0000 - val_loss: 4.7244e-05 - val_accuracy: 1.0000\n","Epoch 193/500\n","1/1 [==============================] - 0s 38ms/step - loss: 3.8903e-05 - accuracy: 1.0000 - val_loss: 4.6841e-05 - val_accuracy: 1.0000\n","Epoch 194/500\n","1/1 [==============================] - 0s 45ms/step - loss: 3.8564e-05 - accuracy: 1.0000 - val_loss: 4.6467e-05 - val_accuracy: 1.0000\n","Epoch 195/500\n","1/1 [==============================] - 0s 35ms/step - loss: 3.8236e-05 - accuracy: 1.0000 - val_loss: 4.6104e-05 - val_accuracy: 1.0000\n","Epoch 196/500\n","1/1 [==============================] - 0s 39ms/step - loss: 3.7897e-05 - accuracy: 1.0000 - val_loss: 4.5718e-05 - val_accuracy: 1.0000\n","Epoch 197/500\n","1/1 [==============================] - 0s 40ms/step - loss: 3.7582e-05 - accuracy: 1.0000 - val_loss: 4.5349e-05 - val_accuracy: 1.0000\n","Epoch 198/500\n","1/1 [==============================] - 0s 49ms/step - loss: 3.7258e-05 - accuracy: 1.0000 - val_loss: 4.4985e-05 - val_accuracy: 1.0000\n","Epoch 199/500\n","1/1 [==============================] - 0s 41ms/step - loss: 3.6938e-05 - accuracy: 1.0000 - val_loss: 4.4605e-05 - val_accuracy: 1.0000\n","Epoch 200/500\n","1/1 [==============================] - 0s 45ms/step - loss: 3.6621e-05 - accuracy: 1.0000 - val_loss: 4.4253e-05 - val_accuracy: 1.0000\n","Epoch 201/500\n","1/1 [==============================] - 0s 39ms/step - loss: 3.6307e-05 - accuracy: 1.0000 - val_loss: 4.3884e-05 - val_accuracy: 1.0000\n","Epoch 202/500\n","1/1 [==============================] - 0s 37ms/step - loss: 3.5989e-05 - accuracy: 1.0000 - val_loss: 4.3527e-05 - val_accuracy: 1.0000\n","Epoch 203/500\n","1/1 [==============================] - 0s 39ms/step - loss: 3.5675e-05 - accuracy: 1.0000 - val_loss: 4.3175e-05 - val_accuracy: 1.0000\n","Epoch 204/500\n","1/1 [==============================] - 0s 49ms/step - loss: 3.5363e-05 - accuracy: 1.0000 - val_loss: 4.2811e-05 - val_accuracy: 1.0000\n","Epoch 205/500\n","1/1 [==============================] - 0s 39ms/step - loss: 3.5066e-05 - accuracy: 1.0000 - val_loss: 4.2459e-05 - val_accuracy: 1.0000\n","Epoch 206/500\n","1/1 [==============================] - 0s 37ms/step - loss: 3.4759e-05 - accuracy: 1.0000 - val_loss: 4.2096e-05 - val_accuracy: 1.0000\n","Epoch 207/500\n","1/1 [==============================] - 0s 41ms/step - loss: 3.4455e-05 - accuracy: 1.0000 - val_loss: 4.1767e-05 - val_accuracy: 1.0000\n","Epoch 208/500\n","1/1 [==============================] - 0s 39ms/step - loss: 3.4163e-05 - accuracy: 1.0000 - val_loss: 4.1404e-05 - val_accuracy: 1.0000\n","Epoch 209/500\n","1/1 [==============================] - 0s 39ms/step - loss: 3.3867e-05 - accuracy: 1.0000 - val_loss: 4.1057e-05 - val_accuracy: 1.0000\n","Epoch 210/500\n","1/1 [==============================] - 0s 36ms/step - loss: 3.3565e-05 - accuracy: 1.0000 - val_loss: 4.0711e-05 - val_accuracy: 1.0000\n","Epoch 211/500\n","1/1 [==============================] - 0s 36ms/step - loss: 3.3268e-05 - accuracy: 1.0000 - val_loss: 4.0371e-05 - val_accuracy: 1.0000\n","Epoch 212/500\n","1/1 [==============================] - 0s 38ms/step - loss: 3.2979e-05 - accuracy: 1.0000 - val_loss: 4.0041e-05 - val_accuracy: 1.0000\n","Epoch 213/500\n","1/1 [==============================] - 0s 42ms/step - loss: 3.2695e-05 - accuracy: 1.0000 - val_loss: 3.9689e-05 - val_accuracy: 1.0000\n","Epoch 214/500\n","1/1 [==============================] - 0s 38ms/step - loss: 3.2408e-05 - accuracy: 1.0000 - val_loss: 3.9372e-05 - val_accuracy: 1.0000\n","Epoch 215/500\n","1/1 [==============================] - 0s 45ms/step - loss: 3.2119e-05 - accuracy: 1.0000 - val_loss: 3.9037e-05 - val_accuracy: 1.0000\n","Epoch 216/500\n","1/1 [==============================] - 0s 40ms/step - loss: 3.1845e-05 - accuracy: 1.0000 - val_loss: 3.8707e-05 - val_accuracy: 1.0000\n","Epoch 217/500\n","1/1 [==============================] - 0s 40ms/step - loss: 3.1559e-05 - accuracy: 1.0000 - val_loss: 3.8384e-05 - val_accuracy: 1.0000\n","Epoch 218/500\n","1/1 [==============================] - 0s 38ms/step - loss: 3.1282e-05 - accuracy: 1.0000 - val_loss: 3.8060e-05 - val_accuracy: 1.0000\n","Epoch 219/500\n","1/1 [==============================] - 0s 36ms/step - loss: 3.1014e-05 - accuracy: 1.0000 - val_loss: 3.7726e-05 - val_accuracy: 1.0000\n","Epoch 220/500\n","1/1 [==============================] - 0s 48ms/step - loss: 3.0737e-05 - accuracy: 1.0000 - val_loss: 3.7408e-05 - val_accuracy: 1.0000\n","Epoch 221/500\n","1/1 [==============================] - 0s 41ms/step - loss: 3.0471e-05 - accuracy: 1.0000 - val_loss: 3.7090e-05 - val_accuracy: 1.0000\n","Epoch 222/500\n","1/1 [==============================] - 0s 40ms/step - loss: 3.0199e-05 - accuracy: 1.0000 - val_loss: 3.6766e-05 - val_accuracy: 1.0000\n","Epoch 223/500\n","1/1 [==============================] - 0s 39ms/step - loss: 2.9931e-05 - accuracy: 1.0000 - val_loss: 3.6454e-05 - val_accuracy: 1.0000\n","Epoch 224/500\n","1/1 [==============================] - 0s 40ms/step - loss: 2.9667e-05 - accuracy: 1.0000 - val_loss: 3.6148e-05 - val_accuracy: 1.0000\n","Epoch 225/500\n","1/1 [==============================] - 0s 39ms/step - loss: 2.9408e-05 - accuracy: 1.0000 - val_loss: 3.5830e-05 - val_accuracy: 1.0000\n","Epoch 226/500\n","1/1 [==============================] - 0s 38ms/step - loss: 2.9147e-05 - accuracy: 1.0000 - val_loss: 3.5529e-05 - val_accuracy: 1.0000\n","Epoch 227/500\n","1/1 [==============================] - 0s 38ms/step - loss: 2.8893e-05 - accuracy: 1.0000 - val_loss: 3.5222e-05 - val_accuracy: 1.0000\n","Epoch 228/500\n","1/1 [==============================] - 0s 37ms/step - loss: 2.8642e-05 - accuracy: 1.0000 - val_loss: 3.4927e-05 - val_accuracy: 1.0000\n","Epoch 229/500\n","1/1 [==============================] - 0s 41ms/step - loss: 2.8386e-05 - accuracy: 1.0000 - val_loss: 3.4615e-05 - val_accuracy: 1.0000\n","Epoch 230/500\n","1/1 [==============================] - 0s 41ms/step - loss: 2.8135e-05 - accuracy: 1.0000 - val_loss: 3.4325e-05 - val_accuracy: 1.0000\n","Epoch 231/500\n","1/1 [==============================] - 0s 39ms/step - loss: 2.7886e-05 - accuracy: 1.0000 - val_loss: 3.4013e-05 - val_accuracy: 1.0000\n","Epoch 232/500\n","1/1 [==============================] - 0s 59ms/step - loss: 2.7643e-05 - accuracy: 1.0000 - val_loss: 3.3729e-05 - val_accuracy: 1.0000\n","Epoch 233/500\n","1/1 [==============================] - 0s 41ms/step - loss: 2.7397e-05 - accuracy: 1.0000 - val_loss: 3.3429e-05 - val_accuracy: 1.0000\n","Epoch 234/500\n","1/1 [==============================] - 0s 44ms/step - loss: 2.7151e-05 - accuracy: 1.0000 - val_loss: 3.3139e-05 - val_accuracy: 1.0000\n","Epoch 235/500\n","1/1 [==============================] - 0s 41ms/step - loss: 2.6910e-05 - accuracy: 1.0000 - val_loss: 3.2850e-05 - val_accuracy: 1.0000\n","Epoch 236/500\n","1/1 [==============================] - 0s 38ms/step - loss: 2.6667e-05 - accuracy: 1.0000 - val_loss: 3.2571e-05 - val_accuracy: 1.0000\n","Epoch 237/500\n","1/1 [==============================] - 0s 40ms/step - loss: 2.6431e-05 - accuracy: 1.0000 - val_loss: 3.2282e-05 - val_accuracy: 1.0000\n","Epoch 238/500\n","1/1 [==============================] - 0s 45ms/step - loss: 2.6202e-05 - accuracy: 1.0000 - val_loss: 3.2004e-05 - val_accuracy: 1.0000\n","Epoch 239/500\n","1/1 [==============================] - 0s 39ms/step - loss: 2.5959e-05 - accuracy: 1.0000 - val_loss: 3.1720e-05 - val_accuracy: 1.0000\n","Epoch 240/500\n","1/1 [==============================] - 0s 36ms/step - loss: 2.5731e-05 - accuracy: 1.0000 - val_loss: 3.1448e-05 - val_accuracy: 1.0000\n","Epoch 241/500\n","1/1 [==============================] - 0s 46ms/step - loss: 2.5507e-05 - accuracy: 1.0000 - val_loss: 3.1175e-05 - val_accuracy: 1.0000\n","Epoch 242/500\n","1/1 [==============================] - 0s 39ms/step - loss: 2.5282e-05 - accuracy: 1.0000 - val_loss: 3.0891e-05 - val_accuracy: 1.0000\n","Epoch 243/500\n","1/1 [==============================] - 0s 39ms/step - loss: 2.5048e-05 - accuracy: 1.0000 - val_loss: 3.0619e-05 - val_accuracy: 1.0000\n","Epoch 244/500\n","1/1 [==============================] - 0s 38ms/step - loss: 2.4828e-05 - accuracy: 1.0000 - val_loss: 3.0358e-05 - val_accuracy: 1.0000\n","Epoch 245/500\n","1/1 [==============================] - 0s 40ms/step - loss: 2.4607e-05 - accuracy: 1.0000 - val_loss: 3.0080e-05 - val_accuracy: 1.0000\n","Epoch 246/500\n","1/1 [==============================] - 0s 40ms/step - loss: 2.4386e-05 - accuracy: 1.0000 - val_loss: 2.9818e-05 - val_accuracy: 1.0000\n","Epoch 247/500\n","1/1 [==============================] - 0s 42ms/step - loss: 2.4173e-05 - accuracy: 1.0000 - val_loss: 2.9569e-05 - val_accuracy: 1.0000\n","Epoch 248/500\n","1/1 [==============================] - 0s 37ms/step - loss: 2.3950e-05 - accuracy: 1.0000 - val_loss: 2.9302e-05 - val_accuracy: 1.0000\n","Epoch 249/500\n","1/1 [==============================] - 0s 43ms/step - loss: 2.3737e-05 - accuracy: 1.0000 - val_loss: 2.9041e-05 - val_accuracy: 1.0000\n","Epoch 250/500\n","1/1 [==============================] - 0s 40ms/step - loss: 2.3529e-05 - accuracy: 1.0000 - val_loss: 2.8791e-05 - val_accuracy: 1.0000\n","Epoch 251/500\n","1/1 [==============================] - 0s 40ms/step - loss: 2.3321e-05 - accuracy: 1.0000 - val_loss: 2.8530e-05 - val_accuracy: 1.0000\n","Epoch 252/500\n","1/1 [==============================] - 0s 36ms/step - loss: 2.3111e-05 - accuracy: 1.0000 - val_loss: 2.8275e-05 - val_accuracy: 1.0000\n","Epoch 253/500\n","1/1 [==============================] - 0s 37ms/step - loss: 2.2903e-05 - accuracy: 1.0000 - val_loss: 2.8025e-05 - val_accuracy: 1.0000\n","Epoch 254/500\n","1/1 [==============================] - 0s 40ms/step - loss: 2.2697e-05 - accuracy: 1.0000 - val_loss: 2.7769e-05 - val_accuracy: 1.0000\n","Epoch 255/500\n","1/1 [==============================] - 0s 40ms/step - loss: 2.2494e-05 - accuracy: 1.0000 - val_loss: 2.7531e-05 - val_accuracy: 1.0000\n","Epoch 256/500\n","1/1 [==============================] - 0s 37ms/step - loss: 2.2299e-05 - accuracy: 1.0000 - val_loss: 2.7293e-05 - val_accuracy: 1.0000\n","Epoch 257/500\n","1/1 [==============================] - 0s 39ms/step - loss: 2.2099e-05 - accuracy: 1.0000 - val_loss: 2.7054e-05 - val_accuracy: 1.0000\n","Epoch 258/500\n","1/1 [==============================] - 0s 38ms/step - loss: 2.1906e-05 - accuracy: 1.0000 - val_loss: 2.6810e-05 - val_accuracy: 1.0000\n","Epoch 259/500\n","1/1 [==============================] - 0s 40ms/step - loss: 2.1703e-05 - accuracy: 1.0000 - val_loss: 2.6566e-05 - val_accuracy: 1.0000\n","Epoch 260/500\n","1/1 [==============================] - 0s 41ms/step - loss: 2.1513e-05 - accuracy: 1.0000 - val_loss: 2.6328e-05 - val_accuracy: 1.0000\n","Epoch 261/500\n","1/1 [==============================] - 0s 38ms/step - loss: 2.1315e-05 - accuracy: 1.0000 - val_loss: 2.6100e-05 - val_accuracy: 1.0000\n","Epoch 262/500\n","1/1 [==============================] - 0s 39ms/step - loss: 2.1135e-05 - accuracy: 1.0000 - val_loss: 2.5862e-05 - val_accuracy: 1.0000\n","Epoch 263/500\n","1/1 [==============================] - 0s 47ms/step - loss: 2.0935e-05 - accuracy: 1.0000 - val_loss: 2.5646e-05 - val_accuracy: 1.0000\n","Epoch 264/500\n","1/1 [==============================] - 0s 38ms/step - loss: 2.0752e-05 - accuracy: 1.0000 - val_loss: 2.5402e-05 - val_accuracy: 1.0000\n","Epoch 265/500\n","1/1 [==============================] - 0s 40ms/step - loss: 2.0569e-05 - accuracy: 1.0000 - val_loss: 2.5192e-05 - val_accuracy: 1.0000\n","Epoch 266/500\n","1/1 [==============================] - 0s 40ms/step - loss: 2.0379e-05 - accuracy: 1.0000 - val_loss: 2.4960e-05 - val_accuracy: 1.0000\n","Epoch 267/500\n","1/1 [==============================] - 0s 40ms/step - loss: 2.0199e-05 - accuracy: 1.0000 - val_loss: 2.4744e-05 - val_accuracy: 1.0000\n","Epoch 268/500\n","1/1 [==============================] - 0s 48ms/step - loss: 2.0024e-05 - accuracy: 1.0000 - val_loss: 2.4528e-05 - val_accuracy: 1.0000\n","Epoch 269/500\n","1/1 [==============================] - 0s 38ms/step - loss: 1.9844e-05 - accuracy: 1.0000 - val_loss: 2.4307e-05 - val_accuracy: 1.0000\n","Epoch 270/500\n","1/1 [==============================] - 0s 39ms/step - loss: 1.9656e-05 - accuracy: 1.0000 - val_loss: 2.4085e-05 - val_accuracy: 1.0000\n","Epoch 271/500\n","1/1 [==============================] - 0s 41ms/step - loss: 1.9484e-05 - accuracy: 1.0000 - val_loss: 2.3875e-05 - val_accuracy: 1.0000\n","Epoch 272/500\n","1/1 [==============================] - 0s 41ms/step - loss: 1.9314e-05 - accuracy: 1.0000 - val_loss: 2.3660e-05 - val_accuracy: 1.0000\n","Epoch 273/500\n","1/1 [==============================] - 0s 42ms/step - loss: 1.9144e-05 - accuracy: 1.0000 - val_loss: 2.3444e-05 - val_accuracy: 1.0000\n","Epoch 274/500\n","1/1 [==============================] - 0s 45ms/step - loss: 1.8974e-05 - accuracy: 1.0000 - val_loss: 2.3245e-05 - val_accuracy: 1.0000\n","Epoch 275/500\n","1/1 [==============================] - 0s 39ms/step - loss: 1.8802e-05 - accuracy: 1.0000 - val_loss: 2.3035e-05 - val_accuracy: 1.0000\n","Epoch 276/500\n","1/1 [==============================] - 0s 42ms/step - loss: 1.8639e-05 - accuracy: 1.0000 - val_loss: 2.2831e-05 - val_accuracy: 1.0000\n","Epoch 277/500\n","1/1 [==============================] - 0s 42ms/step - loss: 1.8477e-05 - accuracy: 1.0000 - val_loss: 2.2644e-05 - val_accuracy: 1.0000\n","Epoch 278/500\n","1/1 [==============================] - 0s 42ms/step - loss: 1.8312e-05 - accuracy: 1.0000 - val_loss: 2.2439e-05 - val_accuracy: 1.0000\n","Epoch 279/500\n","1/1 [==============================] - 0s 41ms/step - loss: 1.8145e-05 - accuracy: 1.0000 - val_loss: 2.2229e-05 - val_accuracy: 1.0000\n","Epoch 280/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.7985e-05 - accuracy: 1.0000 - val_loss: 2.2036e-05 - val_accuracy: 1.0000\n","Epoch 281/500\n","1/1 [==============================] - 0s 44ms/step - loss: 1.7823e-05 - accuracy: 1.0000 - val_loss: 2.1838e-05 - val_accuracy: 1.0000\n","Epoch 282/500\n","1/1 [==============================] - 0s 38ms/step - loss: 1.7668e-05 - accuracy: 1.0000 - val_loss: 2.1645e-05 - val_accuracy: 1.0000\n","Epoch 283/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.7508e-05 - accuracy: 1.0000 - val_loss: 2.1452e-05 - val_accuracy: 1.0000\n","Epoch 284/500\n","1/1 [==============================] - 0s 47ms/step - loss: 1.7356e-05 - accuracy: 1.0000 - val_loss: 2.1264e-05 - val_accuracy: 1.0000\n","Epoch 285/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.7206e-05 - accuracy: 1.0000 - val_loss: 2.1088e-05 - val_accuracy: 1.0000\n","Epoch 286/500\n","1/1 [==============================] - 0s 39ms/step - loss: 1.7047e-05 - accuracy: 1.0000 - val_loss: 2.0895e-05 - val_accuracy: 1.0000\n","Epoch 287/500\n","1/1 [==============================] - 0s 43ms/step - loss: 1.6902e-05 - accuracy: 1.0000 - val_loss: 2.0708e-05 - val_accuracy: 1.0000\n","Epoch 288/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.6750e-05 - accuracy: 1.0000 - val_loss: 2.0526e-05 - val_accuracy: 1.0000\n","Epoch 289/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.6603e-05 - accuracy: 1.0000 - val_loss: 2.0356e-05 - val_accuracy: 1.0000\n","Epoch 290/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.6463e-05 - accuracy: 1.0000 - val_loss: 2.0174e-05 - val_accuracy: 1.0000\n","Epoch 291/500\n","1/1 [==============================] - 0s 37ms/step - loss: 1.6316e-05 - accuracy: 1.0000 - val_loss: 1.9998e-05 - val_accuracy: 1.0000\n","Epoch 292/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.6177e-05 - accuracy: 1.0000 - val_loss: 1.9828e-05 - val_accuracy: 1.0000\n","Epoch 293/500\n","1/1 [==============================] - 0s 45ms/step - loss: 1.6032e-05 - accuracy: 1.0000 - val_loss: 1.9652e-05 - val_accuracy: 1.0000\n","Epoch 294/500\n","1/1 [==============================] - 0s 46ms/step - loss: 1.5895e-05 - accuracy: 1.0000 - val_loss: 1.9482e-05 - val_accuracy: 1.0000\n","Epoch 295/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.5763e-05 - accuracy: 1.0000 - val_loss: 1.9317e-05 - val_accuracy: 1.0000\n","Epoch 296/500\n","1/1 [==============================] - 0s 44ms/step - loss: 1.5619e-05 - accuracy: 1.0000 - val_loss: 1.9136e-05 - val_accuracy: 1.0000\n","Epoch 297/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.5482e-05 - accuracy: 1.0000 - val_loss: 1.8977e-05 - val_accuracy: 1.0000\n","Epoch 298/500\n","1/1 [==============================] - 0s 44ms/step - loss: 1.5352e-05 - accuracy: 1.0000 - val_loss: 1.8812e-05 - val_accuracy: 1.0000\n","Epoch 299/500\n","1/1 [==============================] - 0s 43ms/step - loss: 1.5213e-05 - accuracy: 1.0000 - val_loss: 1.8653e-05 - val_accuracy: 1.0000\n","Epoch 300/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.5081e-05 - accuracy: 1.0000 - val_loss: 1.8483e-05 - val_accuracy: 1.0000\n","Epoch 301/500\n","1/1 [==============================] - 0s 38ms/step - loss: 1.4952e-05 - accuracy: 1.0000 - val_loss: 1.8318e-05 - val_accuracy: 1.0000\n","Epoch 302/500\n","1/1 [==============================] - 0s 41ms/step - loss: 1.4825e-05 - accuracy: 1.0000 - val_loss: 1.8165e-05 - val_accuracy: 1.0000\n","Epoch 303/500\n","1/1 [==============================] - 0s 42ms/step - loss: 1.4695e-05 - accuracy: 1.0000 - val_loss: 1.8006e-05 - val_accuracy: 1.0000\n","Epoch 304/500\n","1/1 [==============================] - 0s 43ms/step - loss: 1.4569e-05 - accuracy: 1.0000 - val_loss: 1.7858e-05 - val_accuracy: 1.0000\n","Epoch 305/500\n","1/1 [==============================] - 0s 49ms/step - loss: 1.4452e-05 - accuracy: 1.0000 - val_loss: 1.7705e-05 - val_accuracy: 1.0000\n","Epoch 306/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.4323e-05 - accuracy: 1.0000 - val_loss: 1.7563e-05 - val_accuracy: 1.0000\n","Epoch 307/500\n","1/1 [==============================] - 0s 54ms/step - loss: 1.4201e-05 - accuracy: 1.0000 - val_loss: 1.7404e-05 - val_accuracy: 1.0000\n","Epoch 308/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.4082e-05 - accuracy: 1.0000 - val_loss: 1.7262e-05 - val_accuracy: 1.0000\n","Epoch 309/500\n","1/1 [==============================] - 0s 38ms/step - loss: 1.3955e-05 - accuracy: 1.0000 - val_loss: 1.7103e-05 - val_accuracy: 1.0000\n","Epoch 310/500\n","1/1 [==============================] - 0s 41ms/step - loss: 1.3843e-05 - accuracy: 1.0000 - val_loss: 1.6979e-05 - val_accuracy: 1.0000\n","Epoch 311/500\n","1/1 [==============================] - 0s 42ms/step - loss: 1.3716e-05 - accuracy: 1.0000 - val_loss: 1.6825e-05 - val_accuracy: 1.0000\n","Epoch 312/500\n","1/1 [==============================] - 0s 48ms/step - loss: 1.3602e-05 - accuracy: 1.0000 - val_loss: 1.6672e-05 - val_accuracy: 1.0000\n","Epoch 313/500\n","1/1 [==============================] - 0s 55ms/step - loss: 1.3486e-05 - accuracy: 1.0000 - val_loss: 1.6536e-05 - val_accuracy: 1.0000\n","Epoch 314/500\n","1/1 [==============================] - 0s 45ms/step - loss: 1.3382e-05 - accuracy: 1.0000 - val_loss: 1.6394e-05 - val_accuracy: 1.0000\n","Epoch 315/500\n","1/1 [==============================] - 0s 38ms/step - loss: 1.3255e-05 - accuracy: 1.0000 - val_loss: 1.6258e-05 - val_accuracy: 1.0000\n","Epoch 316/500\n","1/1 [==============================] - 0s 44ms/step - loss: 1.3156e-05 - accuracy: 1.0000 - val_loss: 1.6116e-05 - val_accuracy: 1.0000\n","Epoch 317/500\n","1/1 [==============================] - 0s 59ms/step - loss: 1.3032e-05 - accuracy: 1.0000 - val_loss: 1.5979e-05 - val_accuracy: 1.0000\n","Epoch 318/500\n","1/1 [==============================] - 0s 45ms/step - loss: 1.2928e-05 - accuracy: 1.0000 - val_loss: 1.5855e-05 - val_accuracy: 1.0000\n","Epoch 319/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.2819e-05 - accuracy: 1.0000 - val_loss: 1.5718e-05 - val_accuracy: 1.0000\n","Epoch 320/500\n","1/1 [==============================] - 0s 39ms/step - loss: 1.2720e-05 - accuracy: 1.0000 - val_loss: 1.5593e-05 - val_accuracy: 1.0000\n","Epoch 321/500\n","1/1 [==============================] - 0s 46ms/step - loss: 1.2608e-05 - accuracy: 1.0000 - val_loss: 1.5469e-05 - val_accuracy: 1.0000\n","Epoch 322/500\n","1/1 [==============================] - 0s 38ms/step - loss: 1.2502e-05 - accuracy: 1.0000 - val_loss: 1.5327e-05 - val_accuracy: 1.0000\n","Epoch 323/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.2398e-05 - accuracy: 1.0000 - val_loss: 1.5207e-05 - val_accuracy: 1.0000\n","Epoch 324/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.2301e-05 - accuracy: 1.0000 - val_loss: 1.5088e-05 - val_accuracy: 1.0000\n","Epoch 325/500\n","1/1 [==============================] - 0s 48ms/step - loss: 1.2195e-05 - accuracy: 1.0000 - val_loss: 1.4958e-05 - val_accuracy: 1.0000\n","Epoch 326/500\n","1/1 [==============================] - 0s 38ms/step - loss: 1.2098e-05 - accuracy: 1.0000 - val_loss: 1.4833e-05 - val_accuracy: 1.0000\n","Epoch 327/500\n","1/1 [==============================] - 0s 49ms/step - loss: 1.1997e-05 - accuracy: 1.0000 - val_loss: 1.4708e-05 - val_accuracy: 1.0000\n","Epoch 328/500\n","1/1 [==============================] - 0s 37ms/step - loss: 1.1900e-05 - accuracy: 1.0000 - val_loss: 1.4577e-05 - val_accuracy: 1.0000\n","Epoch 329/500\n","1/1 [==============================] - 0s 38ms/step - loss: 1.1807e-05 - accuracy: 1.0000 - val_loss: 1.4464e-05 - val_accuracy: 1.0000\n","Epoch 330/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.1710e-05 - accuracy: 1.0000 - val_loss: 1.4350e-05 - val_accuracy: 1.0000\n","Epoch 331/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.1609e-05 - accuracy: 1.0000 - val_loss: 1.4231e-05 - val_accuracy: 1.0000\n","Epoch 332/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.1517e-05 - accuracy: 1.0000 - val_loss: 1.4123e-05 - val_accuracy: 1.0000\n","Epoch 333/500\n","1/1 [==============================] - 0s 43ms/step - loss: 1.1419e-05 - accuracy: 1.0000 - val_loss: 1.4004e-05 - val_accuracy: 1.0000\n","Epoch 334/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.1335e-05 - accuracy: 1.0000 - val_loss: 1.3891e-05 - val_accuracy: 1.0000\n","Epoch 335/500\n","1/1 [==============================] - 0s 38ms/step - loss: 1.1244e-05 - accuracy: 1.0000 - val_loss: 1.3783e-05 - val_accuracy: 1.0000\n","Epoch 336/500\n","1/1 [==============================] - 0s 43ms/step - loss: 1.1152e-05 - accuracy: 1.0000 - val_loss: 1.3669e-05 - val_accuracy: 1.0000\n","Epoch 337/500\n","1/1 [==============================] - 0s 47ms/step - loss: 1.1061e-05 - accuracy: 1.0000 - val_loss: 1.3544e-05 - val_accuracy: 1.0000\n","Epoch 338/500\n","1/1 [==============================] - 0s 38ms/step - loss: 1.0972e-05 - accuracy: 1.0000 - val_loss: 1.3442e-05 - val_accuracy: 1.0000\n","Epoch 339/500\n","1/1 [==============================] - 0s 41ms/step - loss: 1.0883e-05 - accuracy: 1.0000 - val_loss: 1.3334e-05 - val_accuracy: 1.0000\n","Epoch 340/500\n","1/1 [==============================] - 0s 42ms/step - loss: 1.0795e-05 - accuracy: 1.0000 - val_loss: 1.3232e-05 - val_accuracy: 1.0000\n","Epoch 341/500\n","1/1 [==============================] - 0s 39ms/step - loss: 1.0711e-05 - accuracy: 1.0000 - val_loss: 1.3130e-05 - val_accuracy: 1.0000\n","Epoch 342/500\n","1/1 [==============================] - 0s 42ms/step - loss: 1.0630e-05 - accuracy: 1.0000 - val_loss: 1.3028e-05 - val_accuracy: 1.0000\n","Epoch 343/500\n","1/1 [==============================] - 0s 42ms/step - loss: 1.0544e-05 - accuracy: 1.0000 - val_loss: 1.2926e-05 - val_accuracy: 1.0000\n","Epoch 344/500\n","1/1 [==============================] - 0s 43ms/step - loss: 1.0462e-05 - accuracy: 1.0000 - val_loss: 1.2829e-05 - val_accuracy: 1.0000\n","Epoch 345/500\n","1/1 [==============================] - 0s 40ms/step - loss: 1.0381e-05 - accuracy: 1.0000 - val_loss: 1.2715e-05 - val_accuracy: 1.0000\n","Epoch 346/500\n","1/1 [==============================] - 0s 42ms/step - loss: 1.0305e-05 - accuracy: 1.0000 - val_loss: 1.2619e-05 - val_accuracy: 1.0000\n","Epoch 347/500\n","1/1 [==============================] - 0s 51ms/step - loss: 1.0224e-05 - accuracy: 1.0000 - val_loss: 1.2522e-05 - val_accuracy: 1.0000\n","Epoch 348/500\n","1/1 [==============================] - 0s 42ms/step - loss: 1.0138e-05 - accuracy: 1.0000 - val_loss: 1.2426e-05 - val_accuracy: 1.0000\n","Epoch 349/500\n","1/1 [==============================] - 0s 38ms/step - loss: 1.0059e-05 - accuracy: 1.0000 - val_loss: 1.2329e-05 - val_accuracy: 1.0000\n","Epoch 350/500\n","1/1 [==============================] - 0s 40ms/step - loss: 9.9805e-06 - accuracy: 1.0000 - val_loss: 1.2227e-05 - val_accuracy: 1.0000\n","Epoch 351/500\n","1/1 [==============================] - 0s 39ms/step - loss: 9.9069e-06 - accuracy: 1.0000 - val_loss: 1.2142e-05 - val_accuracy: 1.0000\n","Epoch 352/500\n","1/1 [==============================] - 0s 45ms/step - loss: 9.8283e-06 - accuracy: 1.0000 - val_loss: 1.2029e-05 - val_accuracy: 1.0000\n","Epoch 353/500\n","1/1 [==============================] - 0s 45ms/step - loss: 9.7497e-06 - accuracy: 1.0000 - val_loss: 1.1938e-05 - val_accuracy: 1.0000\n","Epoch 354/500\n","1/1 [==============================] - 0s 38ms/step - loss: 9.6761e-06 - accuracy: 1.0000 - val_loss: 1.1864e-05 - val_accuracy: 1.0000\n","Epoch 355/500\n","1/1 [==============================] - 0s 48ms/step - loss: 9.6026e-06 - accuracy: 1.0000 - val_loss: 1.1756e-05 - val_accuracy: 1.0000\n","Epoch 356/500\n","1/1 [==============================] - 0s 42ms/step - loss: 9.5265e-06 - accuracy: 1.0000 - val_loss: 1.1677e-05 - val_accuracy: 1.0000\n","Epoch 357/500\n","1/1 [==============================] - 0s 47ms/step - loss: 9.4580e-06 - accuracy: 1.0000 - val_loss: 1.1592e-05 - val_accuracy: 1.0000\n","Epoch 358/500\n","1/1 [==============================] - 0s 39ms/step - loss: 9.3870e-06 - accuracy: 1.0000 - val_loss: 1.1484e-05 - val_accuracy: 1.0000\n","Epoch 359/500\n","1/1 [==============================] - 0s 46ms/step - loss: 9.3134e-06 - accuracy: 1.0000 - val_loss: 1.1404e-05 - val_accuracy: 1.0000\n","Epoch 360/500\n","1/1 [==============================] - 0s 39ms/step - loss: 9.2424e-06 - accuracy: 1.0000 - val_loss: 1.1325e-05 - val_accuracy: 1.0000\n","Epoch 361/500\n","1/1 [==============================] - 0s 38ms/step - loss: 9.1739e-06 - accuracy: 1.0000 - val_loss: 1.1228e-05 - val_accuracy: 1.0000\n","Epoch 362/500\n","1/1 [==============================] - 0s 37ms/step - loss: 9.1029e-06 - accuracy: 1.0000 - val_loss: 1.1143e-05 - val_accuracy: 1.0000\n","Epoch 363/500\n","1/1 [==============================] - 0s 39ms/step - loss: 9.0395e-06 - accuracy: 1.0000 - val_loss: 1.1064e-05 - val_accuracy: 1.0000\n","Epoch 364/500\n","1/1 [==============================] - 0s 41ms/step - loss: 8.9736e-06 - accuracy: 1.0000 - val_loss: 1.0973e-05 - val_accuracy: 1.0000\n","Epoch 365/500\n","1/1 [==============================] - 0s 40ms/step - loss: 8.9026e-06 - accuracy: 1.0000 - val_loss: 1.0899e-05 - val_accuracy: 1.0000\n","Epoch 366/500\n","1/1 [==============================] - 0s 43ms/step - loss: 8.8366e-06 - accuracy: 1.0000 - val_loss: 1.0808e-05 - val_accuracy: 1.0000\n","Epoch 367/500\n","1/1 [==============================] - 0s 43ms/step - loss: 8.7707e-06 - accuracy: 1.0000 - val_loss: 1.0729e-05 - val_accuracy: 1.0000\n","Epoch 368/500\n","1/1 [==============================] - 0s 53ms/step - loss: 8.7098e-06 - accuracy: 1.0000 - val_loss: 1.0649e-05 - val_accuracy: 1.0000\n","Epoch 369/500\n","1/1 [==============================] - 0s 40ms/step - loss: 8.6439e-06 - accuracy: 1.0000 - val_loss: 1.0575e-05 - val_accuracy: 1.0000\n","Epoch 370/500\n","1/1 [==============================] - 0s 40ms/step - loss: 8.5703e-06 - accuracy: 1.0000 - val_loss: 1.0490e-05 - val_accuracy: 1.0000\n","Epoch 371/500\n","1/1 [==============================] - 0s 40ms/step - loss: 8.5145e-06 - accuracy: 1.0000 - val_loss: 1.0422e-05 - val_accuracy: 1.0000\n","Epoch 372/500\n","1/1 [==============================] - 0s 40ms/step - loss: 8.4562e-06 - accuracy: 1.0000 - val_loss: 1.0343e-05 - val_accuracy: 1.0000\n","Epoch 373/500\n","1/1 [==============================] - 0s 41ms/step - loss: 8.4029e-06 - accuracy: 1.0000 - val_loss: 1.0263e-05 - val_accuracy: 1.0000\n","Epoch 374/500\n","1/1 [==============================] - 0s 38ms/step - loss: 8.3319e-06 - accuracy: 1.0000 - val_loss: 1.0189e-05 - val_accuracy: 1.0000\n","Epoch 375/500\n","1/1 [==============================] - 0s 43ms/step - loss: 8.2685e-06 - accuracy: 1.0000 - val_loss: 1.0121e-05 - val_accuracy: 1.0000\n","Epoch 376/500\n","1/1 [==============================] - 0s 40ms/step - loss: 8.2152e-06 - accuracy: 1.0000 - val_loss: 1.0036e-05 - val_accuracy: 1.0000\n","Epoch 377/500\n","1/1 [==============================] - 0s 42ms/step - loss: 8.1594e-06 - accuracy: 1.0000 - val_loss: 9.9681e-06 - val_accuracy: 1.0000\n","Epoch 378/500\n","1/1 [==============================] - 0s 47ms/step - loss: 8.0935e-06 - accuracy: 1.0000 - val_loss: 9.9000e-06 - val_accuracy: 1.0000\n","Epoch 379/500\n","1/1 [==============================] - 0s 48ms/step - loss: 8.0402e-06 - accuracy: 1.0000 - val_loss: 9.8262e-06 - val_accuracy: 1.0000\n","Epoch 380/500\n","1/1 [==============================] - 0s 39ms/step - loss: 7.9844e-06 - accuracy: 1.0000 - val_loss: 9.7467e-06 - val_accuracy: 1.0000\n","Epoch 381/500\n","1/1 [==============================] - 0s 63ms/step - loss: 7.9286e-06 - accuracy: 1.0000 - val_loss: 9.6899e-06 - val_accuracy: 1.0000\n","Epoch 382/500\n","1/1 [==============================] - 0s 55ms/step - loss: 7.8779e-06 - accuracy: 1.0000 - val_loss: 9.6161e-06 - val_accuracy: 1.0000\n","Epoch 383/500\n","1/1 [==============================] - 0s 68ms/step - loss: 7.8170e-06 - accuracy: 1.0000 - val_loss: 9.5480e-06 - val_accuracy: 1.0000\n","Epoch 384/500\n","1/1 [==============================] - 0s 65ms/step - loss: 7.7587e-06 - accuracy: 1.0000 - val_loss: 9.4856e-06 - val_accuracy: 1.0000\n","Epoch 385/500\n","1/1 [==============================] - 0s 60ms/step - loss: 7.7029e-06 - accuracy: 1.0000 - val_loss: 9.4231e-06 - val_accuracy: 1.0000\n","Epoch 386/500\n","1/1 [==============================] - 0s 60ms/step - loss: 7.6522e-06 - accuracy: 1.0000 - val_loss: 9.3437e-06 - val_accuracy: 1.0000\n","Epoch 387/500\n","1/1 [==============================] - 0s 65ms/step - loss: 7.5964e-06 - accuracy: 1.0000 - val_loss: 9.2755e-06 - val_accuracy: 1.0000\n","Epoch 388/500\n","1/1 [==============================] - 0s 76ms/step - loss: 7.5482e-06 - accuracy: 1.0000 - val_loss: 9.2131e-06 - val_accuracy: 1.0000\n","Epoch 389/500\n","1/1 [==============================] - 0s 72ms/step - loss: 7.4924e-06 - accuracy: 1.0000 - val_loss: 9.1620e-06 - val_accuracy: 1.0000\n","Epoch 390/500\n","1/1 [==============================] - 0s 79ms/step - loss: 7.4442e-06 - accuracy: 1.0000 - val_loss: 9.0882e-06 - val_accuracy: 1.0000\n","Epoch 391/500\n","1/1 [==============================] - 0s 67ms/step - loss: 7.3935e-06 - accuracy: 1.0000 - val_loss: 9.0258e-06 - val_accuracy: 1.0000\n","Epoch 392/500\n","1/1 [==============================] - 0s 66ms/step - loss: 7.3427e-06 - accuracy: 1.0000 - val_loss: 8.9633e-06 - val_accuracy: 1.0000\n","Epoch 393/500\n","1/1 [==============================] - 0s 65ms/step - loss: 7.2895e-06 - accuracy: 1.0000 - val_loss: 8.9122e-06 - val_accuracy: 1.0000\n","Epoch 394/500\n","1/1 [==============================] - 0s 65ms/step - loss: 7.2438e-06 - accuracy: 1.0000 - val_loss: 8.8384e-06 - val_accuracy: 1.0000\n","Epoch 395/500\n","1/1 [==============================] - 0s 45ms/step - loss: 7.1880e-06 - accuracy: 1.0000 - val_loss: 8.7760e-06 - val_accuracy: 1.0000\n","Epoch 396/500\n","1/1 [==============================] - 0s 68ms/step - loss: 7.1398e-06 - accuracy: 1.0000 - val_loss: 8.7136e-06 - val_accuracy: 1.0000\n","Epoch 397/500\n","1/1 [==============================] - 0s 76ms/step - loss: 7.0942e-06 - accuracy: 1.0000 - val_loss: 8.6511e-06 - val_accuracy: 1.0000\n","Epoch 398/500\n","1/1 [==============================] - 0s 46ms/step - loss: 7.0460e-06 - accuracy: 1.0000 - val_loss: 8.6000e-06 - val_accuracy: 1.0000\n","Epoch 399/500\n","1/1 [==============================] - 0s 62ms/step - loss: 6.9978e-06 - accuracy: 1.0000 - val_loss: 8.5376e-06 - val_accuracy: 1.0000\n","Epoch 400/500\n","1/1 [==============================] - 0s 56ms/step - loss: 6.9471e-06 - accuracy: 1.0000 - val_loss: 8.4922e-06 - val_accuracy: 1.0000\n","Epoch 401/500\n","1/1 [==============================] - 0s 67ms/step - loss: 6.9039e-06 - accuracy: 1.0000 - val_loss: 8.4241e-06 - val_accuracy: 1.0000\n","Epoch 402/500\n","1/1 [==============================] - 0s 64ms/step - loss: 6.8583e-06 - accuracy: 1.0000 - val_loss: 8.3673e-06 - val_accuracy: 1.0000\n","Epoch 403/500\n","1/1 [==============================] - 0s 62ms/step - loss: 6.8050e-06 - accuracy: 1.0000 - val_loss: 8.3162e-06 - val_accuracy: 1.0000\n","Epoch 404/500\n","1/1 [==============================] - 0s 77ms/step - loss: 6.7695e-06 - accuracy: 1.0000 - val_loss: 8.2538e-06 - val_accuracy: 1.0000\n","Epoch 405/500\n","1/1 [==============================] - 0s 56ms/step - loss: 6.7163e-06 - accuracy: 1.0000 - val_loss: 8.2027e-06 - val_accuracy: 1.0000\n","Epoch 406/500\n","1/1 [==============================] - 0s 61ms/step - loss: 6.6782e-06 - accuracy: 1.0000 - val_loss: 8.1573e-06 - val_accuracy: 1.0000\n","Epoch 407/500\n","1/1 [==============================] - 0s 61ms/step - loss: 6.6376e-06 - accuracy: 1.0000 - val_loss: 8.0948e-06 - val_accuracy: 1.0000\n","Epoch 408/500\n","1/1 [==============================] - 0s 66ms/step - loss: 6.5920e-06 - accuracy: 1.0000 - val_loss: 8.0494e-06 - val_accuracy: 1.0000\n","Epoch 409/500\n","1/1 [==============================] - 0s 54ms/step - loss: 6.5463e-06 - accuracy: 1.0000 - val_loss: 7.9926e-06 - val_accuracy: 1.0000\n","Epoch 410/500\n","1/1 [==============================] - 0s 47ms/step - loss: 6.5083e-06 - accuracy: 1.0000 - val_loss: 7.9359e-06 - val_accuracy: 1.0000\n","Epoch 411/500\n","1/1 [==============================] - 0s 65ms/step - loss: 6.4601e-06 - accuracy: 1.0000 - val_loss: 7.8905e-06 - val_accuracy: 1.0000\n","Epoch 412/500\n","1/1 [==============================] - 0s 58ms/step - loss: 6.4220e-06 - accuracy: 1.0000 - val_loss: 7.8394e-06 - val_accuracy: 1.0000\n","Epoch 413/500\n","1/1 [==============================] - 0s 52ms/step - loss: 6.3815e-06 - accuracy: 1.0000 - val_loss: 7.7769e-06 - val_accuracy: 1.0000\n","Epoch 414/500\n","1/1 [==============================] - 0s 82ms/step - loss: 6.3434e-06 - accuracy: 1.0000 - val_loss: 7.7372e-06 - val_accuracy: 1.0000\n","Epoch 415/500\n","1/1 [==============================] - 0s 70ms/step - loss: 6.3003e-06 - accuracy: 1.0000 - val_loss: 7.6861e-06 - val_accuracy: 1.0000\n","Epoch 416/500\n","1/1 [==============================] - 0s 65ms/step - loss: 6.2572e-06 - accuracy: 1.0000 - val_loss: 7.6464e-06 - val_accuracy: 1.0000\n","Epoch 417/500\n","1/1 [==============================] - 0s 61ms/step - loss: 6.2217e-06 - accuracy: 1.0000 - val_loss: 7.5839e-06 - val_accuracy: 1.0000\n","Epoch 418/500\n","1/1 [==============================] - 0s 63ms/step - loss: 6.1862e-06 - accuracy: 1.0000 - val_loss: 7.5328e-06 - val_accuracy: 1.0000\n","Epoch 419/500\n","1/1 [==============================] - 0s 53ms/step - loss: 6.1430e-06 - accuracy: 1.0000 - val_loss: 7.4988e-06 - val_accuracy: 1.0000\n","Epoch 420/500\n","1/1 [==============================] - 0s 62ms/step - loss: 6.0999e-06 - accuracy: 1.0000 - val_loss: 7.4420e-06 - val_accuracy: 1.0000\n","Epoch 421/500\n","1/1 [==============================] - 0s 65ms/step - loss: 6.0593e-06 - accuracy: 1.0000 - val_loss: 7.3966e-06 - val_accuracy: 1.0000\n","Epoch 422/500\n","1/1 [==============================] - 0s 57ms/step - loss: 6.0340e-06 - accuracy: 1.0000 - val_loss: 7.3455e-06 - val_accuracy: 1.0000\n","Epoch 423/500\n","1/1 [==============================] - 0s 47ms/step - loss: 5.9833e-06 - accuracy: 1.0000 - val_loss: 7.3001e-06 - val_accuracy: 1.0000\n","Epoch 424/500\n","1/1 [==============================] - 0s 41ms/step - loss: 5.9528e-06 - accuracy: 1.0000 - val_loss: 7.2547e-06 - val_accuracy: 1.0000\n","Epoch 425/500\n","1/1 [==============================] - 0s 49ms/step - loss: 5.9122e-06 - accuracy: 1.0000 - val_loss: 7.2093e-06 - val_accuracy: 1.0000\n","Epoch 426/500\n","1/1 [==============================] - 0s 48ms/step - loss: 5.8767e-06 - accuracy: 1.0000 - val_loss: 7.1639e-06 - val_accuracy: 1.0000\n","Epoch 427/500\n","1/1 [==============================] - 0s 42ms/step - loss: 5.8438e-06 - accuracy: 1.0000 - val_loss: 7.1241e-06 - val_accuracy: 1.0000\n","Epoch 428/500\n","1/1 [==============================] - 0s 45ms/step - loss: 5.8082e-06 - accuracy: 1.0000 - val_loss: 7.0787e-06 - val_accuracy: 1.0000\n","Epoch 429/500\n","1/1 [==============================] - 0s 40ms/step - loss: 5.7702e-06 - accuracy: 1.0000 - val_loss: 7.0333e-06 - val_accuracy: 1.0000\n","Epoch 430/500\n","1/1 [==============================] - 0s 40ms/step - loss: 5.7423e-06 - accuracy: 1.0000 - val_loss: 6.9992e-06 - val_accuracy: 1.0000\n","Epoch 431/500\n","1/1 [==============================] - 0s 47ms/step - loss: 5.6966e-06 - accuracy: 1.0000 - val_loss: 6.9368e-06 - val_accuracy: 1.0000\n","Epoch 432/500\n","1/1 [==============================] - 0s 41ms/step - loss: 5.6738e-06 - accuracy: 1.0000 - val_loss: 6.9141e-06 - val_accuracy: 1.0000\n","Epoch 433/500\n","1/1 [==============================] - 0s 41ms/step - loss: 5.6383e-06 - accuracy: 1.0000 - val_loss: 6.8687e-06 - val_accuracy: 1.0000\n","Epoch 434/500\n","1/1 [==============================] - 0s 39ms/step - loss: 5.6003e-06 - accuracy: 1.0000 - val_loss: 6.8233e-06 - val_accuracy: 1.0000\n","Epoch 435/500\n","1/1 [==============================] - 0s 39ms/step - loss: 5.5673e-06 - accuracy: 1.0000 - val_loss: 6.7779e-06 - val_accuracy: 1.0000\n","Epoch 436/500\n","1/1 [==============================] - 0s 63ms/step - loss: 5.5318e-06 - accuracy: 1.0000 - val_loss: 6.7324e-06 - val_accuracy: 1.0000\n","Epoch 437/500\n","1/1 [==============================] - 0s 42ms/step - loss: 5.5064e-06 - accuracy: 1.0000 - val_loss: 6.7154e-06 - val_accuracy: 1.0000\n","Epoch 438/500\n","1/1 [==============================] - 0s 44ms/step - loss: 5.4734e-06 - accuracy: 1.0000 - val_loss: 6.6643e-06 - val_accuracy: 1.0000\n","Epoch 439/500\n","1/1 [==============================] - 0s 38ms/step - loss: 5.4354e-06 - accuracy: 1.0000 - val_loss: 6.6132e-06 - val_accuracy: 1.0000\n","Epoch 440/500\n","1/1 [==============================] - 0s 39ms/step - loss: 5.4075e-06 - accuracy: 1.0000 - val_loss: 6.5848e-06 - val_accuracy: 1.0000\n","Epoch 441/500\n","1/1 [==============================] - 0s 38ms/step - loss: 5.3745e-06 - accuracy: 1.0000 - val_loss: 6.5394e-06 - val_accuracy: 1.0000\n","Epoch 442/500\n","1/1 [==============================] - 0s 39ms/step - loss: 5.3390e-06 - accuracy: 1.0000 - val_loss: 6.5054e-06 - val_accuracy: 1.0000\n","Epoch 443/500\n","1/1 [==============================] - 0s 47ms/step - loss: 5.3035e-06 - accuracy: 1.0000 - val_loss: 6.4713e-06 - val_accuracy: 1.0000\n","Epoch 444/500\n","1/1 [==============================] - 0s 42ms/step - loss: 5.2756e-06 - accuracy: 1.0000 - val_loss: 6.4316e-06 - val_accuracy: 1.0000\n","Epoch 445/500\n","1/1 [==============================] - 0s 39ms/step - loss: 5.2452e-06 - accuracy: 1.0000 - val_loss: 6.3918e-06 - val_accuracy: 1.0000\n","Epoch 446/500\n","1/1 [==============================] - 0s 52ms/step - loss: 5.2173e-06 - accuracy: 1.0000 - val_loss: 6.3578e-06 - val_accuracy: 1.0000\n","Epoch 447/500\n","1/1 [==============================] - 0s 41ms/step - loss: 5.1868e-06 - accuracy: 1.0000 - val_loss: 6.3067e-06 - val_accuracy: 1.0000\n","Epoch 448/500\n","1/1 [==============================] - 0s 41ms/step - loss: 5.1564e-06 - accuracy: 1.0000 - val_loss: 6.2840e-06 - val_accuracy: 1.0000\n","Epoch 449/500\n","1/1 [==============================] - 0s 41ms/step - loss: 5.1285e-06 - accuracy: 1.0000 - val_loss: 6.2499e-06 - val_accuracy: 1.0000\n","Epoch 450/500\n","1/1 [==============================] - 0s 43ms/step - loss: 5.0955e-06 - accuracy: 1.0000 - val_loss: 6.2045e-06 - val_accuracy: 1.0000\n","Epoch 451/500\n","1/1 [==============================] - 0s 39ms/step - loss: 5.0752e-06 - accuracy: 1.0000 - val_loss: 6.1761e-06 - val_accuracy: 1.0000\n","Epoch 452/500\n","1/1 [==============================] - 0s 39ms/step - loss: 5.0347e-06 - accuracy: 1.0000 - val_loss: 6.1364e-06 - val_accuracy: 1.0000\n","Epoch 453/500\n","1/1 [==============================] - 0s 40ms/step - loss: 5.0169e-06 - accuracy: 1.0000 - val_loss: 6.1080e-06 - val_accuracy: 1.0000\n","Epoch 454/500\n","1/1 [==============================] - 0s 38ms/step - loss: 4.9814e-06 - accuracy: 1.0000 - val_loss: 6.0626e-06 - val_accuracy: 1.0000\n","Epoch 455/500\n","1/1 [==============================] - 0s 40ms/step - loss: 4.9611e-06 - accuracy: 1.0000 - val_loss: 6.0342e-06 - val_accuracy: 1.0000\n","Epoch 456/500\n","1/1 [==============================] - 0s 52ms/step - loss: 4.9307e-06 - accuracy: 1.0000 - val_loss: 5.9888e-06 - val_accuracy: 1.0000\n","Epoch 457/500\n","1/1 [==============================] - 0s 49ms/step - loss: 4.9078e-06 - accuracy: 1.0000 - val_loss: 5.9661e-06 - val_accuracy: 1.0000\n","Epoch 458/500\n","1/1 [==============================] - 0s 41ms/step - loss: 4.8723e-06 - accuracy: 1.0000 - val_loss: 5.9320e-06 - val_accuracy: 1.0000\n","Epoch 459/500\n","1/1 [==============================] - 0s 45ms/step - loss: 4.8495e-06 - accuracy: 1.0000 - val_loss: 5.8923e-06 - val_accuracy: 1.0000\n","Epoch 460/500\n","1/1 [==============================] - 0s 46ms/step - loss: 4.8191e-06 - accuracy: 1.0000 - val_loss: 5.8639e-06 - val_accuracy: 1.0000\n","Epoch 461/500\n","1/1 [==============================] - 0s 40ms/step - loss: 4.7937e-06 - accuracy: 1.0000 - val_loss: 5.8299e-06 - val_accuracy: 1.0000\n","Epoch 462/500\n","1/1 [==============================] - 0s 46ms/step - loss: 4.7683e-06 - accuracy: 1.0000 - val_loss: 5.8072e-06 - val_accuracy: 1.0000\n","Epoch 463/500\n","1/1 [==============================] - 0s 41ms/step - loss: 4.7430e-06 - accuracy: 1.0000 - val_loss: 5.7674e-06 - val_accuracy: 1.0000\n","Epoch 464/500\n","1/1 [==============================] - 0s 40ms/step - loss: 4.7151e-06 - accuracy: 1.0000 - val_loss: 5.7277e-06 - val_accuracy: 1.0000\n","Epoch 465/500\n","1/1 [==============================] - 0s 43ms/step - loss: 4.6923e-06 - accuracy: 1.0000 - val_loss: 5.7050e-06 - val_accuracy: 1.0000\n","Epoch 466/500\n","1/1 [==============================] - 0s 57ms/step - loss: 4.6618e-06 - accuracy: 1.0000 - val_loss: 5.6652e-06 - val_accuracy: 1.0000\n","Epoch 467/500\n","1/1 [==============================] - 0s 50ms/step - loss: 4.6441e-06 - accuracy: 1.0000 - val_loss: 5.6312e-06 - val_accuracy: 1.0000\n","Epoch 468/500\n","1/1 [==============================] - 0s 41ms/step - loss: 4.6162e-06 - accuracy: 1.0000 - val_loss: 5.5915e-06 - val_accuracy: 1.0000\n","Epoch 469/500\n","1/1 [==============================] - 0s 50ms/step - loss: 4.5908e-06 - accuracy: 1.0000 - val_loss: 5.5744e-06 - val_accuracy: 1.0000\n","Epoch 470/500\n","1/1 [==============================] - 0s 44ms/step - loss: 4.5629e-06 - accuracy: 1.0000 - val_loss: 5.5404e-06 - val_accuracy: 1.0000\n","Epoch 471/500\n","1/1 [==============================] - 0s 42ms/step - loss: 4.5401e-06 - accuracy: 1.0000 - val_loss: 5.5120e-06 - val_accuracy: 1.0000\n","Epoch 472/500\n","1/1 [==============================] - 0s 43ms/step - loss: 4.5172e-06 - accuracy: 1.0000 - val_loss: 5.4722e-06 - val_accuracy: 1.0000\n","Epoch 473/500\n","1/1 [==============================] - 0s 43ms/step - loss: 4.4919e-06 - accuracy: 1.0000 - val_loss: 5.4552e-06 - val_accuracy: 1.0000\n","Epoch 474/500\n","1/1 [==============================] - 0s 42ms/step - loss: 4.4691e-06 - accuracy: 1.0000 - val_loss: 5.4268e-06 - val_accuracy: 1.0000\n","Epoch 475/500\n","1/1 [==============================] - 0s 38ms/step - loss: 4.4488e-06 - accuracy: 1.0000 - val_loss: 5.3871e-06 - val_accuracy: 1.0000\n","Epoch 476/500\n","1/1 [==============================] - 0s 44ms/step - loss: 4.4234e-06 - accuracy: 1.0000 - val_loss: 5.3644e-06 - val_accuracy: 1.0000\n","Epoch 477/500\n","1/1 [==============================] - 0s 60ms/step - loss: 4.4031e-06 - accuracy: 1.0000 - val_loss: 5.3360e-06 - val_accuracy: 1.0000\n","Epoch 478/500\n","1/1 [==============================] - 0s 43ms/step - loss: 4.3752e-06 - accuracy: 1.0000 - val_loss: 5.3019e-06 - val_accuracy: 1.0000\n","Epoch 479/500\n","1/1 [==============================] - 0s 44ms/step - loss: 4.3575e-06 - accuracy: 1.0000 - val_loss: 5.2849e-06 - val_accuracy: 1.0000\n","Epoch 480/500\n","1/1 [==============================] - 0s 44ms/step - loss: 4.3296e-06 - accuracy: 1.0000 - val_loss: 5.2509e-06 - val_accuracy: 1.0000\n","Epoch 481/500\n","1/1 [==============================] - 0s 44ms/step - loss: 4.3118e-06 - accuracy: 1.0000 - val_loss: 5.2225e-06 - val_accuracy: 1.0000\n","Epoch 482/500\n","1/1 [==============================] - 0s 42ms/step - loss: 4.2814e-06 - accuracy: 1.0000 - val_loss: 5.1998e-06 - val_accuracy: 1.0000\n","Epoch 483/500\n","1/1 [==============================] - 0s 46ms/step - loss: 4.2636e-06 - accuracy: 1.0000 - val_loss: 5.1714e-06 - val_accuracy: 1.0000\n","Epoch 484/500\n","1/1 [==============================] - 0s 45ms/step - loss: 4.2433e-06 - accuracy: 1.0000 - val_loss: 5.1373e-06 - val_accuracy: 1.0000\n","Epoch 485/500\n","1/1 [==============================] - 0s 40ms/step - loss: 4.2230e-06 - accuracy: 1.0000 - val_loss: 5.1089e-06 - val_accuracy: 1.0000\n","Epoch 486/500\n","1/1 [==============================] - 0s 45ms/step - loss: 4.1926e-06 - accuracy: 1.0000 - val_loss: 5.0919e-06 - val_accuracy: 1.0000\n","Epoch 487/500\n","1/1 [==============================] - 0s 47ms/step - loss: 4.1825e-06 - accuracy: 1.0000 - val_loss: 5.0579e-06 - val_accuracy: 1.0000\n","Epoch 488/500\n","1/1 [==============================] - 0s 43ms/step - loss: 4.1546e-06 - accuracy: 1.0000 - val_loss: 5.0295e-06 - val_accuracy: 1.0000\n","Epoch 489/500\n","1/1 [==============================] - 0s 45ms/step - loss: 4.1343e-06 - accuracy: 1.0000 - val_loss: 5.0124e-06 - val_accuracy: 1.0000\n","Epoch 490/500\n","1/1 [==============================] - 0s 42ms/step - loss: 4.1114e-06 - accuracy: 1.0000 - val_loss: 4.9897e-06 - val_accuracy: 1.0000\n","Epoch 491/500\n","1/1 [==============================] - 0s 47ms/step - loss: 4.0937e-06 - accuracy: 1.0000 - val_loss: 4.9557e-06 - val_accuracy: 1.0000\n","Epoch 492/500\n","1/1 [==============================] - 0s 43ms/step - loss: 4.0759e-06 - accuracy: 1.0000 - val_loss: 4.9386e-06 - val_accuracy: 1.0000\n","Epoch 493/500\n","1/1 [==============================] - 0s 41ms/step - loss: 4.0531e-06 - accuracy: 1.0000 - val_loss: 4.9046e-06 - val_accuracy: 1.0000\n","Epoch 494/500\n","1/1 [==============================] - 0s 41ms/step - loss: 4.0303e-06 - accuracy: 1.0000 - val_loss: 4.8819e-06 - val_accuracy: 1.0000\n","Epoch 495/500\n","1/1 [==============================] - 0s 41ms/step - loss: 4.0049e-06 - accuracy: 1.0000 - val_loss: 4.8535e-06 - val_accuracy: 1.0000\n","Epoch 496/500\n","1/1 [==============================] - 0s 46ms/step - loss: 3.9948e-06 - accuracy: 1.0000 - val_loss: 4.8365e-06 - val_accuracy: 1.0000\n","Epoch 497/500\n","1/1 [==============================] - 0s 62ms/step - loss: 3.9669e-06 - accuracy: 1.0000 - val_loss: 4.8081e-06 - val_accuracy: 1.0000\n","Epoch 498/500\n","1/1 [==============================] - 0s 46ms/step - loss: 3.9516e-06 - accuracy: 1.0000 - val_loss: 4.7911e-06 - val_accuracy: 1.0000\n","Epoch 499/500\n","1/1 [==============================] - 0s 46ms/step - loss: 3.9364e-06 - accuracy: 1.0000 - val_loss: 4.7513e-06 - val_accuracy: 1.0000\n","Epoch 500/500\n","1/1 [==============================] - 0s 42ms/step - loss: 3.9085e-06 - accuracy: 1.0000 - val_loss: 4.7456e-06 - val_accuracy: 1.0000\n","1/1 [==============================] - 0s 27ms/step - loss: 4.0253e-06 - accuracy: 1.0000\n","Test loss is: 0.0000, Test accuracy is: 1.0000\n","1/1 [==============================] - 0s 355ms/step\n","Accuracy is: 1.0000\n","Classification Report is:\n","              precision    recall  f1-score   support\n","\n","      Benign       1.00      1.00      1.00        22\n","     SYNScan       1.00      1.00      1.00         8\n","\n","    accuracy                           1.00        30\n","   macro avg       1.00      1.00      1.00        30\n","weighted avg       1.00      1.00      1.00        30\n","\n","Confusion Matrix is:\n","[[22  0]\n"," [ 0  8]]\n","['SYNScan' 'SYNScan' 'SYNScan' 'SYNScan' 'Benign' 'Benign' 'Benign'\n"," 'SYNScan' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'SYNScan'\n"," 'SYNScan' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n"," 'Benign' 'SYNScan' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign']\n","['SYNScan' 'SYNScan' 'SYNScan' 'SYNScan' 'Benign' 'Benign' 'Benign'\n"," 'SYNScan' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'SYNScan'\n"," 'SYNScan' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n"," 'Benign' 'SYNScan' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign']\n","1/1 [==============================] - 0s 30ms/step - loss: 4.0253e-06 - accuracy: 1.0000\n","Test loss is: 0.0000, Test accuracy is: 1.0000\n","Training time: 0.07 seconds\n","1/1 [==============================] - 0s 19ms/step\n","Class: Benign\n","Precision: 1.0000\n","Recall: 1.0000\n","F1-Score: 1.0000\n","----------------------------------------\n","Class: SYNScan\n","Precision: 1.0000\n","Recall: 1.0000\n","F1-Score: 1.0000\n","----------------------------------------\n","Prediction time: 0.06 seconds\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","\n","# Loading the dataset:-\n","gnidd = pd.read_csv('/content/sample_data/5gnidd.csv')\n","print(gnidd.head())\n","print()\n","unique_columns_before = gnidd.columns.tolist()\n","num_columns_before = len(unique_columns_before)\n","print(f\"Number of columns before dropping: {num_columns_before}\")\n","print(\"Unique columns before dropping:\")\n","print(unique_columns_before)\n","\n","\n","# Describing dataset-\n","gnidd.describe()\n","print()\n","\n","\n","# Dropping unnecessary columns:-\n","unnecessary_columns = ['Unnamed: 0', 'RunTime', 'Min', 'Max', 'sTos', 'dTos',\n","                       'sDSb', 'dDSb', 'sHops', 'dHops', 'SrcWin','DstWin',\n","                       'sVid', 'dVid', 'SrcTCPBase', 'DstTCPBase', 'TcpRtt',\n","                       'SynAck', 'AckDat'\n","                       ]\n","\n","gnidd = gnidd.drop(unnecessary_columns, axis=1)\n","unique_columns_after = gnidd.columns.tolist()\n","num_columns_after = len(unique_columns_after)\n","print(f\"Number of columns after dropping: {num_columns_after}\")\n","print(\"Unique columns after dropping:\")\n","print(unique_columns_after)\n","\n","\n","# Dropping any missing rows:-\n","gnidd = gnidd.dropna()\n","print(gnidd)\n","print()\n","\n","\n","# Checking for duplicate rows:-\n","print(gnidd.duplicated().sum())\n","print()\n","\n","\n","# droping duplicate rows:\n","gnidd = gnidd.drop_duplicates()\n","print(gnidd.shape)\n","print(gnidd.head())\n","print()\n","\n","\n","# Separating feature columns (X) and label columns (Y):-\n","X = gnidd.drop(['Label', 'Attack Type', 'Attack Tool'], axis=1)\n","Y = gnidd['Attack Type']\n","\n","\n","# Converting categorical columns to numerical using one-hot encoding:-\n","categorical_cols = ['Proto', 'Cause', 'State']\n","X = pd.get_dummies(X, columns=categorical_cols)\n","\n","\n","# Performing Feature Selection: ANOVA Method\n","from sklearn.feature_selection import SelectKBest, f_classif\n","k_best = 10\n","anova_selector = SelectKBest(f_classif, k=k_best)\n","X_selected = anova_selector.fit_transform(X, Y)\n","\n","# Print the columns that are observed\n","observed_columns = X.columns.tolist()\n","print(\"Observed columns:\")\n","print(observed_columns)\n","\n","\n","# Print the selected features\n","selected_feature_indices = anova_selector.get_support(indices=True)\n","selected_feature_names = X.columns[selected_feature_indices]\n","print(\"Selected Features:\")\n","print(selected_feature_names)\n","\n","\n","# Converting selected features to a DataFrame\n","selected_feature_indices = anova_selector.get_support(indices=True)\n","selected_feature_names = X.columns[selected_feature_indices]\n","X_selected_df = pd.DataFrame(X_selected, columns=selected_feature_names)\n","\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","col_to_scale = ['Seq','Dur','Mean','Sum','TotPkts','SrcPkts','DstPkts','TotBytes',\n","                'SrcBytes','DstBytes','Offset','sMeanPktSz','dMeanPktSz','Load','SrcLoad',\n","                'DstLoad','Loss','SrcLoss','DstLoss','pLoss','Rate','SrcRate','DstRate',\n","                'SrcGap','DstGap','sTtl','dTtl'\n","                ]\n","\n","numeric_data = gnidd[col_to_scale]\n","# Min-Max Scaling:-\n","min_max_sclaing = MinMaxScaler()\n","\n","# Applying Z-Score Normalization:-\n","standard_scaling = StandardScaler()\n","standard_scaled_data = standard_scaling.fit_transform(numeric_data)\n","standard_scaled_data = pd.DataFrame(standard_scaled_data, columns = col_to_scale)\n","\n","# Converting dataframe to a numpy array:-\n","X = X.to_numpy()\n","\n","# Converting labels to numerical values:-\n","label_encoder = LabelEncoder()\n","Y = label_encoder.fit_transform(Y)\n","\n","# Converting target labels to one-hot encoding:-\n","numerical_classes = len(label_encoder.classes_)\n","Y = tf.keras.utils.to_categorical(Y, numerical_classes)\n","print('Encoded Labels: ', Y)\n","print()\n","\n","# Splitting data into training and testing sets:-\n","X_train, X_test, Y_train, Y_test = train_test_split(X,\n","                                                    Y,\n","                                                    test_size=0.3,\n","                                                    random_state=42)\n","\n","# Reshaping input data for our RNN (assuming that the dataset has 1D sequences):-\n","input_shape = (X_train.shape[1], 1)\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n","\n","# Building our RNN model:-\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.LSTM(128, input_shape=input_shape),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(numerical_classes, activation='softmax')\n","])\n","\n","# Model Compilation:-\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","# Training our Model:-\n","epochs = 500\n","batch_size = 128\n","history = model.fit(X_train,\n","                    Y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_split=0.3)\n","\n","# Model Evaluation:-\n","loss, accuracy = model.evaluate(X_test, Y_test, batch_size=batch_size)\n","print(f'Test loss is: {loss:.4f}, Test accuracy is: {accuracy:.4f}')\n","\n","# Making predictions:-\n","y_pred = model.predict(X_test)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_test_classes = np.argmax(Y_test, axis=1)\n","\n","# Converting predicted labels back to original ones:-\n","y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n","y_test_labels = label_encoder.inverse_transform(y_test_classes)\n","\n","# Calculating accuracy:-\n","accuracy = accuracy_score(y_test_labels, y_pred_labels)\n","print(f'Accuracy is: {accuracy:.4f}')\n","\n","# Generating classification report:-\n","classification_rep = classification_report(y_test_labels, y_pred_labels)\n","print('Classification Report is:')\n","print(classification_rep)\n","\n","# Generating Confusion Matrix:-\n","confusion_mat = confusion_matrix(y_test_labels, y_pred_labels)\n","print('Confusion Matrix is:')\n","print(confusion_mat)\n","\n","# Printing predected val:-\n","print(y_pred_labels)\n","print(y_test_labels)\n","\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import time\n","\n","# ... (Your previous code)\n","# Model Evaluation:-\n","start_time = time.time()\n","loss, accuracy = model.evaluate(X_test, Y_test, batch_size=batch_size)\n","end_time = time.time()\n","training_time = end_time - start_time\n","\n","print(f'Test loss is: {loss:.4f}, Test accuracy is: {accuracy:.4f}')\n","print(f'Training time: {training_time:.2f} seconds')\n","\n","# Making predictions:-\n","start_time = time.time()\n","y_pred = model.predict(X_test)\n","end_time = time.time()\n","prediction_time = end_time - start_time\n","\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_test_classes = np.argmax(Y_test, axis=1)\n","\n","# Calculate precision, recall, F1-score for each class\n","class_names = label_encoder.classes_\n","for i in range(len(class_names)):\n","    class_label = class_names[i]\n","    class_indices = np.where(y_test_classes == i)[0]\n","\n","    precision = precision_score(y_test_classes[class_indices], y_pred_classes[class_indices], average='weighted')\n","    recall = recall_score(y_test_classes[class_indices], y_pred_classes[class_indices], average='weighted')\n","    f1 = f1_score(y_test_classes[class_indices], y_pred_classes[class_indices], average='weighted')\n","\n","    print(f\"Class: {class_label}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1-Score: {f1:.4f}\")\n","    print(\"-\" * 40)\n","\n","print(f'Prediction time: {prediction_time:.2f} seconds')"]},{"cell_type":"markdown","source":["At Batch size 50(less) and 100 epochs(more) with 80:20 split and val split 0.2 accuracy = 100%"],"metadata":{"id":"utzMTJGLaXVG"}}]}